{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees in Practice\n",
    "\n",
    "* Implement binary decision trees with different early stopping methods.\n",
    "* Compare models with different stopping parameters.\n",
    "* Visualize the concept of overfitting in decision trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('lending-club-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>pub_rec_zero</th>\n",
       "      <th>collections_12_mths_zero</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>final_d</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_record_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.14350</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.39320</td>\n",
       "      <td>20161201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.25955</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27585</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075269</td>\n",
       "      <td>1311441</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.90</td>\n",
       "      <td>156.46</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.21533</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501    1296599       5000         5000             4975   36 months   \n",
       "1  1077430    1314167       2500         2500             2500   60 months   \n",
       "2  1077175    1313524       2400         2400             2400   36 months   \n",
       "3  1076863    1277178      10000        10000            10000   36 months   \n",
       "4  1075269    1311441       5000         5000             5000   36 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade          ...          sub_grade_num  \\\n",
       "0     10.65       162.87     B        B2          ...                    0.4   \n",
       "1     15.27        59.83     C        C4          ...                    0.8   \n",
       "2     15.96        84.33     C        C5          ...                    1.0   \n",
       "3     13.49       339.31     C        C1          ...                    0.2   \n",
       "4      7.90       156.46     A        A4          ...                    0.8   \n",
       "\n",
       "  delinq_2yrs_zero pub_rec_zero  collections_12_mths_zero short_emp  \\\n",
       "0              1.0          1.0                       1.0         0   \n",
       "1              1.0          1.0                       1.0         1   \n",
       "2              1.0          1.0                       1.0         0   \n",
       "3              1.0          1.0                       1.0         0   \n",
       "4              1.0          1.0                       1.0         0   \n",
       "\n",
       "  payment_inc_ratio          final_d last_delinq_none last_record_none  \\\n",
       "0           8.14350  20141201T000000                1                1   \n",
       "1           2.39320  20161201T000000                1                1   \n",
       "2           8.25955  20141201T000000                1                1   \n",
       "3           8.27585  20141201T000000                0                1   \n",
       "4           5.21533  20141201T000000                1                1   \n",
       "\n",
       "  last_major_derog_none  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x: +1 if x==0 else -1)\n",
    "loans = loans.drop(['bad_loans'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsample dataset to be balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train-idx.json', 'r') as f:\n",
    "    train_idx = json.load(f)\n",
    "    \n",
    "with open('validation-idx.json', 'r') as f:\n",
    "    validation_idx = json.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoding_binary_feature(data, y_label):\n",
    "    labels =  data.select_dtypes(include=[object])\n",
    "    encoded_features =[]\n",
    "    #encoded_values = np.transpose(np.array(np.ones(len(data),)))\n",
    "    encoded_values = pd.DataFrame(data[y_label])   \n",
    "    \n",
    "    for label in labels:\n",
    "        \n",
    "        distinct_features = list(set(data[label].values))\n",
    "    \n",
    "        for feature in distinct_features:\n",
    "            encoded_features.append(str(label + '.'+feature))\n",
    "            \n",
    "            #new_array = np.array(np.ones(len(data),))\n",
    "            encoded_values[encoded_features[-1]] = data[label].apply(lambda x : +1 if x==feature else 0)\n",
    "    \n",
    "    return encoded_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['safe_loans' 'grade.F' 'grade.A' 'grade.B' 'grade.E' 'grade.C' 'grade.G'\n",
      " 'grade.D' 'term. 36 months' 'term. 60 months' 'home_ownership.OWN'\n",
      " 'home_ownership.OTHER' 'home_ownership.MORTGAGE' 'home_ownership.RENT'\n",
      " 'emp_length.9 years' 'emp_length.< 1 year' 'emp_length.n/a'\n",
      " 'emp_length.7 years' 'emp_length.8 years' 'emp_length.3 years'\n",
      " 'emp_length.4 years' 'emp_length.5 years' 'emp_length.6 years'\n",
      " 'emp_length.10+ years' 'emp_length.1 year' 'emp_length.2 years']\n"
     ]
    }
   ],
   "source": [
    "loans_data = encoding_binary_feature(loans,'safe_loans')\n",
    "print(loans_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = loans_data.iloc[train_idx].drop(['safe_loans'], axis = 1)\n",
    "train_Y = loans_data['safe_loans'].iloc[train_idx]\n",
    "\n",
    "test_data = loans_data.iloc[validation_idx].drop(['safe_loans'], axis = 1)\n",
    "test_Y = loans_data['safe_loans'].iloc[validation_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe loan percentage:  50.2236174422\n"
     ]
    }
   ],
   "source": [
    "safe_loans = (train_Y == 1).sum() + (test_Y ==1).sum()\n",
    "bad_loans = (train_Y == -1).sum() + (test_Y == -1).sum()\n",
    "percentage = (safe_loans/(safe_loans + bad_loans)*100)\n",
    "print('Safe loan percentage: ', percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree implementation\n",
    "\n",
    "In this section, we will implement binary decision trees from scratch. There are several steps involved in building a decision tree. For that reason, we have split the entire assignment into several sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping methods for decision trees\n",
    "\n",
    "In this section, we will extend the **binary tree implementation** from the previous assignment in order to handle some early stopping conditions. Recall the 3 early stopping methods that were discussed in lecture:\n",
    "\n",
    "1. Reached a **maximum depth**. (set by parameter `max_depth`).\n",
    "2. Reached a **minimum node size**. (set by parameter `min_node_size`).\n",
    "3. Don't split if the **gain in error reduction** is too small. (set by parameter `min_error_reduction`).\n",
    "\n",
    "For the rest of this assignment, we will refer to these three as **early stopping conditions 1, 2, and 3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reached_minimum_node_size(data, min_node_size):\n",
    "    # Return True if the number of data points is less than or equal to the minimum node size.\n",
    "    return True if (data.shape)[0]<=min_node_size else False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_reduction(error_before_split, error_after_split):\n",
    "    # Return the error before the split minus the error after the split.\n",
    "    print(\"old error: \", error_before_split)\n",
    "    print(\"new error: \", error_after_split)\n",
    "    return (error_before_split - error_after_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intermediate_node_num_mistakes(labels_in_node, key_value):\n",
    "    # Corner case: If labels_in_node is empty, return 0\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0\n",
    "    \n",
    "    if(key_value == -1):\n",
    "        return (labels_in_node==1).sum()\n",
    "    elif key_value == 1:\n",
    "        return (labels_in_node==-1).sum()\n",
    "    else:\n",
    "        num_safe_loans = (labels_in_node==1).sum()\n",
    "    \n",
    "        # Count the number of -1's (risky loans)\n",
    "        num_risky_loans = (labels_in_node ==-1).sum()\n",
    "                \n",
    "        # Return the number of mistakes that the majority classifier makes.\n",
    "        return num_safe_loans if num_safe_loans < num_risky_loans else num_risky_loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target):\n",
    "    \n",
    "    best_feature = None # Keep track of the best feature \n",
    "    best_error = 10     # Keep track of the best error so far \n",
    "    # Note: Since error is always <= 1, we should intialize it with something larger than 1.\n",
    "\n",
    "    # Convert to float to make sure error gets computed correctly.\n",
    "    num_data_points = float(len(target))  \n",
    "    \n",
    "    # Loop through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        #print(feature)\n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        left_split = target[data[feature] == 0]\n",
    "        \n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        right_split =  target[data[feature] == 1]\n",
    "            \n",
    "        # Calculate the number of misclassified examples in the left split.\n",
    "        # Remember that we implemented a function for this! (It was called intermediate_node_num_mistakes)\n",
    "        left_mistakes =  intermediate_node_num_mistakes(left_split, -1)           \n",
    "\n",
    "        # Calculate the number of misclassified examples in the right split.\n",
    "        right_mistakes = intermediate_node_num_mistakes(right_split, 1)      \n",
    "            \n",
    "        # Compute the classification error of this split.\n",
    "        # Error = (# of mistakes (left) + # of mistakes (right)) / (# of data points)\n",
    "        error = (left_mistakes + right_mistakes) / num_data_points\n",
    "        #print(str(error) + feature)\n",
    "        # If this is the best error we have found so far, store the feature as best_feature and the error as best_error\n",
    "        if error <best_error:\n",
    "            best_error = error\n",
    "            best_feature = feature\n",
    "        \n",
    "    return best_feature # Return the best feature we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_leaf(target_values):\n",
    "    \n",
    "    # Create a leaf node\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf': True    }   \n",
    "    \n",
    "    # Count the number of data points that are +1 and -1 in this node.\n",
    "    num_ones = len(target_values[target_values == +1])\n",
    "    num_minus_ones = len(target_values[target_values == -1])\n",
    "    \n",
    "    # For the leaf node, set the prediction to be the majority class.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    if num_ones > num_minus_ones:\n",
    "        leaf['prediction'] =          1\n",
    "    else:\n",
    "        leaf['prediction'] =          -1\n",
    "        \n",
    "    # Return the leaf node        \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_create(data, features, target, current_depth = 0, \n",
    "                         max_depth = 10, min_node_size=1, \n",
    "                         min_error_reduction=0.0):\n",
    "    \n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    \n",
    "    target_values = target\n",
    "    print (\"--------------------------------------------------------------------\")\n",
    "    print (\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "    \n",
    "\n",
    "    # Stopping condition 1\n",
    "    # (Check if there are mistakes at current node.\n",
    "    # Recall you wrote a function intermediate_node_num_mistakes to compute this.)\n",
    "    if intermediate_node_num_mistakes(target,0) == 0: \n",
    "        print (\"Stopping condition 1 reached.\" )    \n",
    "        # If not mistakes at current node, make current node a leaf node\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Stopping condition 2 (check if there are remaining features to consider splitting on)\n",
    "    if len(remaining_features) == 0: \n",
    "        print (\"Stopping condition 2 reached.\")    \n",
    "        # If there are no remaining features to consider, make current node a leaf node\n",
    "        return create_leaf(target_values)    \n",
    "    \n",
    "    # Additional stopping condition (limit tree depth)\n",
    "    if current_depth >= max_depth: \n",
    "        print (\"Reached maximum depth. Stopping for now.\")\n",
    "        # If the max tree depth has been reached, make current node a leaf node\n",
    "        return create_leaf(target_values)\n",
    "\n",
    "    # If the min_size of node reached\n",
    "    \n",
    "    # Early stopping condition 2: Reached the minimum node size.\n",
    "    # If the number of data points is less than or equal to the minimum size, return a leaf.\n",
    "    if  reached_minimum_node_size(data, min_node_size): \n",
    "        print (\"Early stopping condition 2 reached. Reached minimum node size.\")\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Find the best splitting feature (recall the function best_splitting_feature implemented above)\n",
    "    error_before_split = intermediate_node_num_mistakes(target_values, 0) / float(len(data))\n",
    "    \n",
    "    splitting_feature = best_splitting_feature(data, remaining_features, target_values)\n",
    "    \n",
    "    # Split on the best feature that we found. \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    left_target = target_values[data[splitting_feature] == 0]\n",
    "    \n",
    "    right_split = data[data[splitting_feature] == 1] \n",
    "    right_target = target_values[data[splitting_feature] == 1]\n",
    "    \n",
    "                                                                                  \n",
    "    left_mistakes =  intermediate_node_num_mistakes(left_target, -1)           \n",
    "    right_mistakes = intermediate_node_num_mistakes(right_target, 1)   \n",
    "    \n",
    "    error_after_split = (left_mistakes + right_mistakes) / float(len(data))\n",
    "    \n",
    "    if (error_reduction(error_before_split, error_after_split)) <= min_error_reduction:\n",
    "        print (\"Early stopping condition 3 reached. Minimum error reduction.\")\n",
    "        return create_leaf(target_values)\n",
    "                                                                                                                                                             \n",
    "                                                                                  \n",
    "    #remaining_features =  remaining_features.remove(splitting_feature)\n",
    "    remaining_features = [x for x in remaining_features if x != splitting_feature]\n",
    "    \n",
    "    print (\"Split on feature %s. (%s, %s)\" % (\\\n",
    "                      splitting_feature, len(left_split), len(right_split)))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print (\"Creating leaf node.\")\n",
    "        return create_leaf(left_target)\n",
    "    if len(right_split) == len(data):\n",
    "        print (\"Creating leaf node.\")\n",
    "        return create_leaf(right_target)\n",
    "\n",
    "        \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = decision_tree_create(left_split, remaining_features, left_target, current_depth + 1, max_depth, min_node_size, \n",
    "                         min_error_reduction)\n",
    "\n",
    "    right_tree = decision_tree_create(right_split, remaining_features, right_target, current_depth + 1, max_depth, min_node_size, min_error_reduction) \n",
    "\n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade.F</th>\n",
       "      <th>grade.A</th>\n",
       "      <th>grade.B</th>\n",
       "      <th>grade.E</th>\n",
       "      <th>grade.C</th>\n",
       "      <th>grade.G</th>\n",
       "      <th>grade.D</th>\n",
       "      <th>term. 36 months</th>\n",
       "      <th>term. 60 months</th>\n",
       "      <th>home_ownership.OWN</th>\n",
       "      <th>...</th>\n",
       "      <th>emp_length.n/a</th>\n",
       "      <th>emp_length.7 years</th>\n",
       "      <th>emp_length.8 years</th>\n",
       "      <th>emp_length.3 years</th>\n",
       "      <th>emp_length.4 years</th>\n",
       "      <th>emp_length.5 years</th>\n",
       "      <th>emp_length.6 years</th>\n",
       "      <th>emp_length.10+ years</th>\n",
       "      <th>emp_length.1 year</th>\n",
       "      <th>emp_length.2 years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   grade.F  grade.A  grade.B  grade.E  grade.C  grade.G  grade.D  \\\n",
       "1        0        0        0        0        1        0        0   \n",
       "6        1        0        0        0        0        0        0   \n",
       "\n",
       "   term. 36 months  term. 60 months  home_ownership.OWN         ...          \\\n",
       "1                0                1                   0         ...           \n",
       "6                0                1                   1         ...           \n",
       "\n",
       "   emp_length.n/a  emp_length.7 years  emp_length.8 years  emp_length.3 years  \\\n",
       "1               0                   0                   0                   0   \n",
       "6               0                   0                   0                   0   \n",
       "\n",
       "   emp_length.4 years  emp_length.5 years  emp_length.6 years  \\\n",
       "1                   0                   0                   0   \n",
       "6                   1                   0                   0   \n",
       "\n",
       "   emp_length.10+ years  emp_length.1 year  emp_length.2 years  \n",
       "1                     0                  0                   0  \n",
       "6                     0                  0                   0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1   -1\n",
       "6   -1\n",
       "Name: safe_loans, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "old error:  0.496346443155\n",
      "new error:  0.421636578551\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "old error:  0.349235606636\n",
      "new error:  0.34674184105\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "old error:  0.346305634729\n",
      "new error:  0.346415259811\n",
      "Split on feature home_ownership.OTHER. (9119, 3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9119 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "old error:  0.386138613861\n",
      "new error:  0.386138613861\n",
      "Split on feature term. 60 months. (0, 101)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "old error:  0.445484089854\n",
      "new error:  0.461983500589\n",
      "Split on feature grade.A. (22972, 5029)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (22972 data points).\n",
      "old error:  0.489944279993\n",
      "new error:  0.43143827268\n",
      "Split on feature grade.B. (13654, 9318)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13654 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9318 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5029 data points).\n",
      "old error:  0.242394114138\n",
      "new error:  0.443626963611\n",
      "Split on feature home_ownership.MORTGAGE. (2282, 2747)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2282 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2747 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "Test failed... try again!\n",
      "Number of nodes found                : 13\n",
      "Number of nodes that should be there : 7\n"
     ]
    }
   ],
   "source": [
    "small_decision_tree = decision_tree_create(train_data, features, train_Y, max_depth = 3, \n",
    "                                        min_node_size = 0, min_error_reduction=-1)\n",
    "if count_nodes(small_decision_tree) == 7:\n",
    "    print ('Test passed!')\n",
    "else:\n",
    "    print ('Test failed... try again!')\n",
    "    print ('Number of nodes found                :', count_nodes(small_decision_tree))\n",
    "    print ('Number of nodes that should be there : 7' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a tree!\n",
    "\n",
    "Now that your code is working, we will train a tree model on the **train_data** with\n",
    "* `max_depth = 6`\n",
    "* `min_node_size = 100`, \n",
    "* `min_error_reduction = 0.0`\n",
    "\n",
    "**Warning**: This code block may take a minute to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "old error:  0.496346443155\n",
      "new error:  0.421636578551\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "old error:  0.349235606636\n",
      "new error:  0.34674184105\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "old error:  0.346305634729\n",
      "new error:  0.346415259811\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "old error:  0.386138613861\n",
      "new error:  0.386138613861\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "old error:  0.445484089854\n",
      "new error:  0.461983500589\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree_new = decision_tree_create(train_data, features, train_Y, max_depth = 6, \n",
    "                                min_node_size = 100, min_error_reduction=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "old error:  0.496346443155\n",
      "new error:  0.421636578551\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "old error:  0.349235606636\n",
      "new error:  0.34674184105\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "old error:  0.346305634729\n",
      "new error:  0.346415259811\n",
      "Split on feature home_ownership.OTHER. (9119, 3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9119 data points).\n",
      "old error:  0.346309902402\n",
      "new error:  0.358701612019\n",
      "Split on feature emp_length.n/a. (8898, 221)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (8898 data points).\n",
      "old error:  0.348842436503\n",
      "new error:  0.362553382783\n",
      "Split on feature grade.B. (7884, 1014)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (7884 data points).\n",
      "old error:  0.337138508371\n",
      "new error:  0.354261796043\n",
      "Split on feature emp_length.8 years. (7507, 377)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7507 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (377 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1014 data points).\n",
      "old error:  0.439842209073\n",
      "new error:  0.436883629191\n",
      "Split on feature emp_length.5 years. (935, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (935 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (79 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (221 data points).\n",
      "old error:  0.244343891403\n",
      "new error:  0.244343891403\n",
      "Split on feature grade.G. (215, 6)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (215 data points).\n",
      "old error:  0.237209302326\n",
      "new error:  0.237209302326\n",
      "Split on feature emp_length.9 years. (215, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (6 data points).\n",
      "old error:  0.5\n",
      "new error:  0.166666666667\n",
      "Split on feature home_ownership.OWN. (4, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (4 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3 data points).\n",
      "old error:  0.333333333333\n",
      "new error:  0.0\n",
      "Split on feature grade.F. (2, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "old error:  0.386138613861\n",
      "new error:  0.386138613861\n",
      "Split on feature term. 60 months. (0, 101)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "old error:  0.445484089854\n",
      "new error:  0.461983500589\n",
      "Split on feature grade.A. (22972, 5029)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (22972 data points).\n",
      "old error:  0.489944279993\n",
      "new error:  0.43143827268\n",
      "Split on feature grade.B. (13654, 9318)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13654 data points).\n",
      "old error:  0.450783653142\n",
      "new error:  0.450783653142\n",
      "Split on feature term. 60 months. (13654, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9318 data points).\n",
      "old error:  0.403090792015\n",
      "new error:  0.484331401588\n",
      "Split on feature home_ownership.MORTGAGE. (4975, 4343)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4975 data points).\n",
      "old error:  0.42391959799\n",
      "new error:  0.454472361809\n",
      "Split on feature home_ownership.RENT. (738, 4237)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (738 data points).\n",
      "old error:  0.39701897019\n",
      "new error:  0.390243902439\n",
      "Split on feature home_ownership.OWN. (17, 721)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (17 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (721 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4237 data points).\n",
      "old error:  0.42860514515\n",
      "new error:  0.543072928959\n",
      "Split on feature emp_length.2 years. (3741, 496)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3741 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (496 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4343 data points).\n",
      "old error:  0.37923094635\n",
      "new error:  0.533041676261\n",
      "Split on feature emp_length.10+ years. (2846, 1497)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2846 data points).\n",
      "old error:  0.382642304989\n",
      "new error:  0.581869290232\n",
      "Split on feature emp_length.2 years. (2513, 333)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2513 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (333 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1497 data points).\n",
      "old error:  0.372745490982\n",
      "new error:  0.627254509018\n",
      "Split on feature grade.F. (1497, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5029 data points).\n",
      "old error:  0.242394114138\n",
      "new error:  0.443626963611\n",
      "Split on feature home_ownership.MORTGAGE. (2282, 2747)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2282 data points).\n",
      "old error:  0.278264680105\n",
      "new error:  0.382559158633\n",
      "Split on feature home_ownership.RENT. (458, 1824)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (458 data points).\n",
      "old error:  0.240174672489\n",
      "new error:  0.255458515284\n",
      "Split on feature home_ownership.OWN. (9, 449)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (9 data points).\n",
      "old error:  0.111111111111\n",
      "new error:  0.111111111111\n",
      "Split on feature home_ownership.OTHER. (0, 9)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (449 data points).\n",
      "old error:  0.24276169265\n",
      "new error:  0.599109131403\n",
      "Split on feature emp_length.10+ years. (318, 131)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (318 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (131 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1824 data points).\n",
      "old error:  0.287828947368\n",
      "new error:  0.644188596491\n",
      "Split on feature emp_length.< 1 year. (1564, 260)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1564 data points).\n",
      "old error:  0.292199488491\n",
      "new error:  0.642583120205\n",
      "Split on feature emp_length.2 years. (1332, 232)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1332 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (232 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (260 data points).\n",
      "old error:  0.261538461538\n",
      "new error:  0.738461538462\n",
      "Split on feature grade.F. (260, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2747 data points).\n",
      "old error:  0.212595558791\n",
      "new error:  0.578085183837\n",
      "Split on feature emp_length.10+ years. (1770, 977)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1770 data points).\n",
      "old error:  0.216384180791\n",
      "new error:  0.709039548023\n",
      "Split on feature emp_length.4 years. (1584, 186)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1584 data points).\n",
      "old error:  0.224747474747\n",
      "new error:  0.695707070707\n",
      "Split on feature emp_length.2 years. (1380, 204)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1380 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (204 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (186 data points).\n",
      "old error:  0.145161290323\n",
      "new error:  0.854838709677\n",
      "Split on feature grade.F. (186, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (977 data points).\n",
      "old error:  0.205731832139\n",
      "new error:  0.794268167861\n",
      "Split on feature grade.F. (977, 0)\n",
      "Creating leaf node.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree_old = decision_tree_create(train_data, features, train_Y, max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print (\"At leaf, predicting %s\" % tree['prediction'])\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print (\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: -1 \n"
     ]
    }
   ],
   "source": [
    "print ('Predicted class: %s ' % classify(my_decision_tree_new, test_data.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on term. 36 months = 0\n",
      "Split on grade.A = 0\n",
      "At leaf, predicting -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(my_decision_tree_new, test_data.iloc[0], annotate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on term. 36 months = 0\n",
      "Split on grade.A = 0\n",
      "Split on home_ownership.OTHER = 0\n",
      "Split on emp_length.n/a = 0\n",
      "Split on grade.B = 0\n",
      "Split on emp_length.8 years = 0\n",
      "At leaf, predicting -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(my_decision_tree_old, test_data.iloc[0], annotate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data, target):\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    #prediction = data.apply(lambda x: classify(tree, x))\n",
    "    prediction =[]\n",
    "    for i in range(len(data)):\n",
    "        prediction.append(classify(tree, data.iloc[i]))\n",
    "    \n",
    "    # Once you've made the predictions, calculate the classification error and return it\n",
    "    errors = (prediction == target).sum()/len(target)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57733735458853941"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(my_decision_tree_new, test_data, test_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61805256355019389"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(my_decision_tree_old, test_data, test_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57898130238555767"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(my_decision_tree_new, train_data, train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61538254889318722"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(my_decision_tree_old, train_data, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the effect of max_depth\n",
    "\n",
    "We will compare three models trained with different values of the stopping criterion. We intentionally picked models at the extreme ends (**too small**, **just right**, and **too large**).\n",
    "\n",
    "Train three models with these parameters:\n",
    "\n",
    "1. **model_1**: max_depth = 2 (too small)\n",
    "2. **model_2**: max_depth = 6 (just right)\n",
    "3. **model_3**: max_depth = 14 (may be too large)\n",
    "\n",
    "For each of these three, we set `min_node_size = 0` and `min_error_reduction = -1`.\n",
    "\n",
    "** Note:** Each tree can take up to a few minutes to train. In particular, `model_3` will probably take the longest to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "old error:  0.496346443155\n",
      "new error:  0.421636578551\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "old error:  0.349235606636\n",
      "new error:  0.34674184105\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "old error:  0.445484089854\n",
      "new error:  0.461983500589\n",
      "Split on feature grade.A. (22972, 5029)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (22972 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5029 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "old error:  0.496346443155\n",
      "new error:  0.421636578551\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "old error:  0.349235606636\n",
      "new error:  0.34674184105\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "old error:  0.346305634729\n",
      "new error:  0.346415259811\n",
      "Split on feature home_ownership.OTHER. (9119, 3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9119 data points).\n",
      "old error:  0.346309902402\n",
      "new error:  0.358701612019\n",
      "Split on feature emp_length.n/a. (8898, 221)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (8898 data points).\n",
      "old error:  0.348842436503\n",
      "new error:  0.362553382783\n",
      "Split on feature grade.B. (7884, 1014)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (7884 data points).\n",
      "old error:  0.337138508371\n",
      "new error:  0.354261796043\n",
      "Split on feature emp_length.8 years. (7507, 377)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7507 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (377 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1014 data points).\n",
      "old error:  0.439842209073\n",
      "new error:  0.436883629191\n",
      "Split on feature emp_length.5 years. (935, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (935 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (79 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (221 data points).\n",
      "old error:  0.244343891403\n",
      "new error:  0.244343891403\n",
      "Split on feature grade.G. (215, 6)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (215 data points).\n",
      "old error:  0.237209302326\n",
      "new error:  0.237209302326\n",
      "Split on feature emp_length.9 years. (215, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (6 data points).\n",
      "old error:  0.5\n",
      "new error:  0.166666666667\n",
      "Split on feature home_ownership.OWN. (4, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (4 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3 data points).\n",
      "old error:  0.333333333333\n",
      "new error:  0.0\n",
      "Split on feature grade.F. (2, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "old error:  0.386138613861\n",
      "new error:  0.386138613861\n",
      "Split on feature term. 60 months. (0, 101)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "old error:  0.445484089854\n",
      "new error:  0.461983500589\n",
      "Split on feature grade.A. (22972, 5029)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (22972 data points).\n",
      "old error:  0.489944279993\n",
      "new error:  0.43143827268\n",
      "Split on feature grade.B. (13654, 9318)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13654 data points).\n",
      "old error:  0.450783653142\n",
      "new error:  0.450783653142\n",
      "Split on feature term. 60 months. (13654, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9318 data points).\n",
      "old error:  0.403090792015\n",
      "new error:  0.484331401588\n",
      "Split on feature home_ownership.MORTGAGE. (4975, 4343)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4975 data points).\n",
      "old error:  0.42391959799\n",
      "new error:  0.454472361809\n",
      "Split on feature home_ownership.RENT. (738, 4237)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (738 data points).\n",
      "old error:  0.39701897019\n",
      "new error:  0.390243902439\n",
      "Split on feature home_ownership.OWN. (17, 721)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (17 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (721 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4237 data points).\n",
      "old error:  0.42860514515\n",
      "new error:  0.543072928959\n",
      "Split on feature emp_length.2 years. (3741, 496)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3741 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (496 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4343 data points).\n",
      "old error:  0.37923094635\n",
      "new error:  0.533041676261\n",
      "Split on feature emp_length.10+ years. (2846, 1497)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2846 data points).\n",
      "old error:  0.382642304989\n",
      "new error:  0.581869290232\n",
      "Split on feature emp_length.2 years. (2513, 333)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2513 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (333 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1497 data points).\n",
      "old error:  0.372745490982\n",
      "new error:  0.627254509018\n",
      "Split on feature grade.F. (1497, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5029 data points).\n",
      "old error:  0.242394114138\n",
      "new error:  0.443626963611\n",
      "Split on feature home_ownership.MORTGAGE. (2282, 2747)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2282 data points).\n",
      "old error:  0.278264680105\n",
      "new error:  0.382559158633\n",
      "Split on feature home_ownership.RENT. (458, 1824)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (458 data points).\n",
      "old error:  0.240174672489\n",
      "new error:  0.255458515284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature home_ownership.OWN. (9, 449)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (9 data points).\n",
      "old error:  0.111111111111\n",
      "new error:  0.111111111111\n",
      "Split on feature home_ownership.OTHER. (0, 9)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (449 data points).\n",
      "old error:  0.24276169265\n",
      "new error:  0.599109131403\n",
      "Split on feature emp_length.10+ years. (318, 131)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (318 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (131 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1824 data points).\n",
      "old error:  0.287828947368\n",
      "new error:  0.644188596491\n",
      "Split on feature emp_length.< 1 year. (1564, 260)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1564 data points).\n",
      "old error:  0.292199488491\n",
      "new error:  0.642583120205\n",
      "Split on feature emp_length.2 years. (1332, 232)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1332 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (232 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (260 data points).\n",
      "old error:  0.261538461538\n",
      "new error:  0.738461538462\n",
      "Split on feature grade.F. (260, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2747 data points).\n",
      "old error:  0.212595558791\n",
      "new error:  0.578085183837\n",
      "Split on feature emp_length.10+ years. (1770, 977)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1770 data points).\n",
      "old error:  0.216384180791\n",
      "new error:  0.709039548023\n",
      "Split on feature emp_length.4 years. (1584, 186)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1584 data points).\n",
      "old error:  0.224747474747\n",
      "new error:  0.695707070707\n",
      "Split on feature emp_length.2 years. (1380, 204)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1380 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (204 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (186 data points).\n",
      "old error:  0.145161290323\n",
      "new error:  0.854838709677\n",
      "Split on feature grade.F. (186, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (977 data points).\n",
      "old error:  0.205731832139\n",
      "new error:  0.794268167861\n",
      "Split on feature grade.F. (977, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "old error:  0.496346443155\n",
      "new error:  0.421636578551\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "old error:  0.349235606636\n",
      "new error:  0.34674184105\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "old error:  0.346305634729\n",
      "new error:  0.346415259811\n",
      "Split on feature home_ownership.OTHER. (9119, 3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9119 data points).\n",
      "old error:  0.346309902402\n",
      "new error:  0.358701612019\n",
      "Split on feature emp_length.n/a. (8898, 221)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (8898 data points).\n",
      "old error:  0.348842436503\n",
      "new error:  0.362553382783\n",
      "Split on feature grade.B. (7884, 1014)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (7884 data points).\n",
      "old error:  0.337138508371\n",
      "new error:  0.354261796043\n",
      "Split on feature emp_length.8 years. (7507, 377)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7507 data points).\n",
      "old error:  0.337951245504\n",
      "new error:  0.356600506194\n",
      "Split on feature emp_length.9 years. (7163, 344)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (7163 data points).\n",
      "old error:  0.33994136535\n",
      "new error:  0.361301130811\n",
      "Split on feature emp_length.4 years. (6664, 499)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (6664 data points).\n",
      "old error:  0.33943577431\n",
      "new error:  0.361494597839\n",
      "Split on feature grade.G. (6383, 281)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (6383 data points).\n",
      "old error:  0.343882187059\n",
      "new error:  0.365345448849\n",
      "Split on feature emp_length.7 years. (5926, 457)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (5926 data points).\n",
      "old error:  0.343401957476\n",
      "new error:  0.366689166385\n",
      "Split on feature home_ownership.OWN. (5488, 438)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (5488 data points).\n",
      "old error:  0.343476676385\n",
      "new error:  0.367346938776\n",
      "Split on feature emp_length.1 year. (5089, 399)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (5089 data points).\n",
      "old error:  0.344075456868\n",
      "new error:  0.377873845549\n",
      "Split on feature emp_length.5 years. (4535, 554)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (4535 data points).\n",
      "old error:  0.343991179713\n",
      "new error:  0.381918412348\n",
      "Split on feature emp_length.6 years. (4107, 428)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (4107 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (428 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (554 data points).\n",
      "old error:  0.34476534296\n",
      "new error:  0.34476534296\n",
      "Split on feature emp_length.< 1 year. (554, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (399 data points).\n",
      "old error:  0.335839598997\n",
      "new error:  0.335839598997\n",
      "Split on feature emp_length.< 1 year. (399, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (438 data points).\n",
      "old error:  0.342465753425\n",
      "new error:  0.342465753425\n",
      "Split on feature home_ownership.MORTGAGE. (438, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (457 data points).\n",
      "old error:  0.35010940919\n",
      "new error:  0.35010940919\n",
      "Split on feature emp_length.< 1 year. (457, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (281 data points).\n",
      "old error:  0.238434163701\n",
      "new error:  0.238434163701\n",
      "Split on feature grade.F. (281, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (499 data points).\n",
      "old error:  0.346693386774\n",
      "new error:  0.346693386774\n",
      "Split on feature emp_length.< 1 year. (499, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (344 data points).\n",
      "old error:  0.296511627907\n",
      "new error:  0.296511627907\n",
      "Split on feature emp_length.< 1 year. (344, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (377 data points).\n",
      "old error:  0.320954907162\n",
      "new error:  0.320954907162\n",
      "Split on feature emp_length.9 years. (377, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1014 data points).\n",
      "old error:  0.439842209073\n",
      "new error:  0.436883629191\n",
      "Split on feature emp_length.5 years. (935, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (935 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error:  0.433155080214\n",
      "new error:  0.433155080214\n",
      "Split on feature grade.F. (935, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (79 data points).\n",
      "old error:  0.481012658228\n",
      "new error:  0.481012658228\n",
      "Split on feature term. 60 months. (0, 79)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (221 data points).\n",
      "old error:  0.244343891403\n",
      "new error:  0.244343891403\n",
      "Split on feature grade.G. (215, 6)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (215 data points).\n",
      "old error:  0.237209302326\n",
      "new error:  0.237209302326\n",
      "Split on feature emp_length.9 years. (215, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (6 data points).\n",
      "old error:  0.5\n",
      "new error:  0.166666666667\n",
      "Split on feature home_ownership.OWN. (4, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (4 data points).\n",
      "old error:  0.25\n",
      "new error:  0.25\n",
      "Split on feature grade.F. (4, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3 data points).\n",
      "old error:  0.333333333333\n",
      "new error:  0.0\n",
      "Split on feature grade.F. (2, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "old error:  0.386138613861\n",
      "new error:  0.386138613861\n",
      "Split on feature term. 60 months. (0, 101)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "old error:  0.445484089854\n",
      "new error:  0.461983500589\n",
      "Split on feature grade.A. (22972, 5029)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (22972 data points).\n",
      "old error:  0.489944279993\n",
      "new error:  0.43143827268\n",
      "Split on feature grade.B. (13654, 9318)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13654 data points).\n",
      "old error:  0.450783653142\n",
      "new error:  0.450783653142\n",
      "Split on feature term. 60 months. (13654, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9318 data points).\n",
      "old error:  0.403090792015\n",
      "new error:  0.484331401588\n",
      "Split on feature home_ownership.MORTGAGE. (4975, 4343)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4975 data points).\n",
      "old error:  0.42391959799\n",
      "new error:  0.454472361809\n",
      "Split on feature home_ownership.RENT. (738, 4237)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (738 data points).\n",
      "old error:  0.39701897019\n",
      "new error:  0.390243902439\n",
      "Split on feature home_ownership.OWN. (17, 721)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (17 data points).\n",
      "old error:  0.352941176471\n",
      "new error:  0.294117647059\n",
      "Split on feature emp_length.< 1 year. (16, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (16 data points).\n",
      "old error:  0.3125\n",
      "new error:  0.25\n",
      "Split on feature emp_length.3 years. (15, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (15 data points).\n",
      "old error:  0.266666666667\n",
      "new error:  0.2\n",
      "Split on feature emp_length.4 years. (14, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (14 data points).\n",
      "old error:  0.214285714286\n",
      "new error:  0.142857142857\n",
      "Split on feature emp_length.1 year. (13, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (13 data points).\n",
      "old error:  0.153846153846\n",
      "new error:  0.153846153846\n",
      "Split on feature grade.F. (13, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (721 data points).\n",
      "old error:  0.391123439667\n",
      "new error:  0.539528432732\n",
      "Split on feature emp_length.10+ years. (535, 186)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (535 data points).\n",
      "old error:  0.4\n",
      "new error:  0.54953271028\n",
      "Split on feature emp_length.< 1 year. (458, 77)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (458 data points).\n",
      "old error:  0.412663755459\n",
      "new error:  0.53056768559\n",
      "Split on feature emp_length.4 years. (404, 54)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (404 data points).\n",
      "old error:  0.433168316832\n",
      "new error:  0.532178217822\n",
      "Split on feature emp_length.3 years. (346, 58)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (346 data points).\n",
      "old error:  0.442196531792\n",
      "new error:  0.520231213873\n",
      "Split on feature emp_length.2 years. (279, 67)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (279 data points).\n",
      "old error:  0.451612903226\n",
      "new error:  0.512544802867\n",
      "Split on feature emp_length.7 years. (247, 32)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (247 data points).\n",
      "old error:  0.465587044534\n",
      "new error:  0.493927125506\n",
      "Split on feature emp_length.1 year. (201, 46)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (201 data points).\n",
      "old error:  0.482587064677\n",
      "new error:  0.477611940299\n",
      "Split on feature emp_length.5 years. (161, 40)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (161 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (40 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (46 data points).\n",
      "old error:  0.391304347826\n",
      "new error:  0.608695652174\n",
      "Split on feature grade.F. (46, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (32 data points).\n",
      "old error:  0.34375\n",
      "new error:  0.65625\n",
      "Split on feature grade.F. (32, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (67 data points).\n",
      "old error:  0.402985074627\n",
      "new error:  0.597014925373\n",
      "Split on feature grade.F. (67, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (58 data points).\n",
      "old error:  0.379310344828\n",
      "new error:  0.620689655172\n",
      "Split on feature grade.F. (58, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (54 data points).\n",
      "old error:  0.259259259259\n",
      "new error:  0.740740740741\n",
      "Split on feature grade.F. (54, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (77 data points).\n",
      "old error:  0.324675324675\n",
      "new error:  0.675324675325\n",
      "Split on feature grade.F. (77, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (186 data points).\n",
      "old error:  0.365591397849\n",
      "new error:  0.634408602151\n",
      "Split on feature grade.F. (186, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4237 data points).\n",
      "old error:  0.42860514515\n",
      "new error:  0.543072928959\n",
      "Split on feature emp_length.2 years. (3741, 496)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3741 data points).\n",
      "old error:  0.435177759957\n",
      "new error:  0.539160652232\n",
      "Split on feature emp_length.10+ years. (2963, 778)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (2963 data points).\n",
      "old error:  0.434357070537\n",
      "new error:  0.537293283834\n",
      "Split on feature emp_length.3 years. (2527, 436)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2527 data points).\n",
      "old error:  0.439651760981\n",
      "new error:  0.527502967946\n",
      "Split on feature emp_length.< 1 year. (2014, 513)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (2014 data points).\n",
      "old error:  0.444885799404\n",
      "new error:  0.518371400199\n",
      "Split on feature emp_length.5 years. (1648, 366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (1648 data points).\n",
      "old error:  0.455097087379\n",
      "new error:  0.507281553398\n",
      "Split on feature emp_length.1 year. (1270, 378)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (1270 data points).\n",
      "old error:  0.466141732283\n",
      "new error:  0.491338582677\n",
      "Split on feature emp_length.4 years. (916, 354)\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtree, depth = 12 (916 data points).\n",
      "old error:  0.482532751092\n",
      "new error:  0.470524017467\n",
      "Split on feature emp_length.6 years. (639, 277)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (639 data points).\n",
      "old error:  0.491392801252\n",
      "new error:  0.464788732394\n",
      "Split on feature emp_length.8 years. (466, 173)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (466 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (173 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (277 data points).\n",
      "old error:  0.42238267148\n",
      "new error:  0.57761732852\n",
      "Split on feature grade.F. (277, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (354 data points).\n",
      "old error:  0.423728813559\n",
      "new error:  0.576271186441\n",
      "Split on feature grade.F. (354, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (378 data points).\n",
      "old error:  0.417989417989\n",
      "new error:  0.582010582011\n",
      "Split on feature grade.F. (378, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (366 data points).\n",
      "old error:  0.398907103825\n",
      "new error:  0.601092896175\n",
      "Split on feature grade.F. (366, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (513 data points).\n",
      "old error:  0.41910331384\n",
      "new error:  0.58089668616\n",
      "Split on feature grade.F. (513, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (436 data points).\n",
      "old error:  0.403669724771\n",
      "new error:  0.596330275229\n",
      "Split on feature grade.F. (436, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (778 data points).\n",
      "old error:  0.438303341902\n",
      "new error:  0.561696658098\n",
      "Split on feature grade.F. (778, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (496 data points).\n",
      "old error:  0.379032258065\n",
      "new error:  0.620967741935\n",
      "Split on feature grade.F. (496, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4343 data points).\n",
      "old error:  0.37923094635\n",
      "new error:  0.533041676261\n",
      "Split on feature emp_length.10+ years. (2846, 1497)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2846 data points).\n",
      "old error:  0.382642304989\n",
      "new error:  0.581869290232\n",
      "Split on feature emp_length.2 years. (2513, 333)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2513 data points).\n",
      "old error:  0.387186629526\n",
      "new error:  0.575009948269\n",
      "Split on feature emp_length.3 years. (2182, 331)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (2182 data points).\n",
      "old error:  0.391842346471\n",
      "new error:  0.565994500458\n",
      "Split on feature emp_length.4 years. (1904, 278)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1904 data points).\n",
      "old error:  0.400210084034\n",
      "new error:  0.564600840336\n",
      "Split on feature emp_length.5 years. (1561, 343)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1561 data points).\n",
      "old error:  0.399743754004\n",
      "new error:  0.561178731582\n",
      "Split on feature emp_length.8 years. (1342, 219)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (1342 data points).\n",
      "old error:  0.406110283159\n",
      "new error:  0.549925484352\n",
      "Split on feature emp_length.7 years. (1083, 259)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (1083 data points).\n",
      "old error:  0.410895660203\n",
      "new error:  0.536472760849\n",
      "Split on feature emp_length.1 year. (872, 211)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (872 data points).\n",
      "old error:  0.422018348624\n",
      "new error:  0.518348623853\n",
      "Split on feature emp_length.6 years. (598, 274)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (598 data points).\n",
      "old error:  0.429765886288\n",
      "new error:  0.498327759197\n",
      "Split on feature emp_length.< 1 year. (329, 269)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (329 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (269 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (274 data points).\n",
      "old error:  0.405109489051\n",
      "new error:  0.594890510949\n",
      "Split on feature grade.F. (274, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (211 data points).\n",
      "old error:  0.364928909953\n",
      "new error:  0.635071090047\n",
      "Split on feature grade.F. (211, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (259 data points).\n",
      "old error:  0.3861003861\n",
      "new error:  0.6138996139\n",
      "Split on feature grade.F. (259, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (219 data points).\n",
      "old error:  0.360730593607\n",
      "new error:  0.639269406393\n",
      "Split on feature grade.F. (219, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (343 data points).\n",
      "old error:  0.402332361516\n",
      "new error:  0.597667638484\n",
      "Split on feature grade.F. (343, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (278 data points).\n",
      "old error:  0.334532374101\n",
      "new error:  0.665467625899\n",
      "Split on feature grade.F. (278, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (331 data points).\n",
      "old error:  0.356495468278\n",
      "new error:  0.643504531722\n",
      "Split on feature grade.F. (331, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (333 data points).\n",
      "old error:  0.348348348348\n",
      "new error:  0.651651651652\n",
      "Split on feature grade.F. (333, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1497 data points).\n",
      "old error:  0.372745490982\n",
      "new error:  0.627254509018\n",
      "Split on feature grade.F. (1497, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5029 data points).\n",
      "old error:  0.242394114138\n",
      "new error:  0.443626963611\n",
      "Split on feature home_ownership.MORTGAGE. (2282, 2747)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2282 data points).\n",
      "old error:  0.278264680105\n",
      "new error:  0.382559158633\n",
      "Split on feature home_ownership.RENT. (458, 1824)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (458 data points).\n",
      "old error:  0.240174672489\n",
      "new error:  0.255458515284\n",
      "Split on feature home_ownership.OWN. (9, 449)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (9 data points).\n",
      "old error:  0.111111111111\n",
      "new error:  0.111111111111\n",
      "Split on feature home_ownership.OTHER. (0, 9)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (449 data points).\n",
      "old error:  0.24276169265\n",
      "new error:  0.599109131403\n",
      "Split on feature emp_length.10+ years. (318, 131)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (318 data points).\n",
      "old error:  0.248427672956\n",
      "new error:  0.663522012579\n",
      "Split on feature emp_length.< 1 year. (272, 46)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (272 data points).\n",
      "old error:  0.257352941176\n",
      "new error:  0.658088235294\n",
      "Split on feature emp_length.3 years. (235, 37)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (235 data points).\n",
      "old error:  0.268085106383\n",
      "new error:  0.63829787234\n",
      "Split on feature emp_length.n/a. (187, 48)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (187 data points).\n",
      "old error:  0.267379679144\n",
      "new error:  0.641711229947\n",
      "Split on feature emp_length.2 years. (150, 37)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (150 data points).\n",
      "old error:  0.266666666667\n",
      "new error:  0.64\n",
      "Split on feature emp_length.6 years. (126, 24)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (126 data points).\n",
      "old error:  0.277777777778\n",
      "new error:  0.611111111111\n",
      "Split on feature emp_length.1 year. (108, 18)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (108 data points).\n",
      "old error:  0.305555555556\n",
      "new error:  0.583333333333\n",
      "Split on feature emp_length.4 years. (82, 26)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (82 data points).\n",
      "old error:  0.317073170732\n",
      "new error:  0.560975609756\n",
      "Split on feature emp_length.7 years. (62, 20)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (62 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (20 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (26 data points).\n",
      "old error:  0.269230769231\n",
      "new error:  0.730769230769\n",
      "Split on feature grade.F. (26, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (18 data points).\n",
      "old error:  0.111111111111\n",
      "new error:  0.888888888889\n",
      "Split on feature grade.F. (18, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (24 data points).\n",
      "old error:  0.208333333333\n",
      "new error:  0.791666666667\n",
      "Split on feature grade.F. (24, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (37 data points).\n",
      "old error:  0.27027027027\n",
      "new error:  0.72972972973\n",
      "Split on feature grade.F. (37, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (48 data points).\n",
      "old error:  0.270833333333\n",
      "new error:  0.729166666667\n",
      "Split on feature grade.F. (48, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (37 data points).\n",
      "old error:  0.189189189189\n",
      "new error:  0.810810810811\n",
      "Split on feature grade.F. (37, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (46 data points).\n",
      "old error:  0.195652173913\n",
      "new error:  0.804347826087\n",
      "Split on feature grade.F. (46, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (131 data points).\n",
      "old error:  0.229007633588\n",
      "new error:  0.770992366412\n",
      "Split on feature grade.F. (131, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1824 data points).\n",
      "old error:  0.287828947368\n",
      "new error:  0.644188596491\n",
      "Split on feature emp_length.< 1 year. (1564, 260)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1564 data points).\n",
      "old error:  0.292199488491\n",
      "new error:  0.642583120205\n",
      "Split on feature emp_length.2 years. (1332, 232)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1332 data points).\n",
      "old error:  0.294294294294\n",
      "new error:  0.631381381381\n",
      "Split on feature emp_length.10+ years. (1051, 281)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (1051 data points).\n",
      "old error:  0.286393910561\n",
      "new error:  0.63177925785\n",
      "Split on feature emp_length.3 years. (877, 174)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (877 data points).\n",
      "old error:  0.293044469783\n",
      "new error:  0.60889395667\n",
      "Split on feature emp_length.1 year. (677, 200)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (677 data points).\n",
      "old error:  0.295420974889\n",
      "new error:  0.579025110783\n",
      "Split on feature emp_length.4 years. (502, 175)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (502 data points).\n",
      "old error:  0.308764940239\n",
      "new error:  0.549800796813\n",
      "Split on feature emp_length.5 years. (347, 155)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (347 data points).\n",
      "old error:  0.325648414986\n",
      "new error:  0.538904899135\n",
      "Split on feature emp_length.6 years. (238, 109)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (238 data points).\n",
      "old error:  0.344537815126\n",
      "new error:  0.525210084034\n",
      "Split on feature emp_length.8 years. (179, 59)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (179 data points).\n",
      "old error:  0.379888268156\n",
      "new error:  0.525139664804\n",
      "Split on feature emp_length.n/a. (108, 71)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (108 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (71 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (59 data points).\n",
      "old error:  0.237288135593\n",
      "new error:  0.762711864407\n",
      "Split on feature grade.F. (59, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (109 data points).\n",
      "old error:  0.284403669725\n",
      "new error:  0.715596330275\n",
      "Split on feature grade.F. (109, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (155 data points).\n",
      "old error:  0.270967741935\n",
      "new error:  0.729032258065\n",
      "Split on feature grade.F. (155, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (175 data points).\n",
      "old error:  0.257142857143\n",
      "new error:  0.742857142857\n",
      "Split on feature grade.F. (175, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (200 data points).\n",
      "old error:  0.285\n",
      "new error:  0.715\n",
      "Split on feature grade.F. (200, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (174 data points).\n",
      "old error:  0.252873563218\n",
      "new error:  0.747126436782\n",
      "Split on feature grade.F. (174, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (281 data points).\n",
      "old error:  0.32384341637\n",
      "new error:  0.67615658363\n",
      "Split on feature grade.F. (281, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (232 data points).\n",
      "old error:  0.280172413793\n",
      "new error:  0.719827586207\n",
      "Split on feature grade.F. (232, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (260 data points).\n",
      "old error:  0.261538461538\n",
      "new error:  0.738461538462\n",
      "Split on feature grade.F. (260, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2747 data points).\n",
      "old error:  0.212595558791\n",
      "new error:  0.578085183837\n",
      "Split on feature emp_length.10+ years. (1770, 977)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1770 data points).\n",
      "old error:  0.216384180791\n",
      "new error:  0.709039548023\n",
      "Split on feature emp_length.4 years. (1584, 186)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1584 data points).\n",
      "old error:  0.224747474747\n",
      "new error:  0.695707070707\n",
      "Split on feature emp_length.2 years. (1380, 204)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1380 data points).\n",
      "old error:  0.229710144928\n",
      "new error:  0.68768115942\n",
      "Split on feature emp_length.3 years. (1176, 204)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (1176 data points).\n",
      "old error:  0.231292517007\n",
      "new error:  0.674319727891\n",
      "Split on feature emp_length.< 1 year. (1001, 175)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1001 data points).\n",
      "old error:  0.23976023976\n",
      "new error:  0.653346653347\n",
      "Split on feature emp_length.5 years. (804, 197)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (804 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error:  0.242537313433\n",
      "new error:  0.638059701493\n",
      "Split on feature emp_length.6 years. (646, 158)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (646 data points).\n",
      "old error:  0.25386996904\n",
      "new error:  0.609907120743\n",
      "Split on feature emp_length.9 years. (510, 136)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (510 data points).\n",
      "old error:  0.274509803922\n",
      "new error:  0.570588235294\n",
      "Split on feature emp_length.1 year. (369, 141)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (369 data points).\n",
      "old error:  0.29539295393\n",
      "new error:  0.50135501355\n",
      "Split on feature emp_length.7 years. (224, 145)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (224 data points).\n",
      "old error:  0.330357142857\n",
      "new error:  0.40625\n",
      "Split on feature emp_length.8 years. (111, 113)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (111 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (113 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (145 data points).\n",
      "old error:  0.241379310345\n",
      "new error:  0.758620689655\n",
      "Split on feature grade.F. (145, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (141 data points).\n",
      "old error:  0.219858156028\n",
      "new error:  0.780141843972\n",
      "Split on feature grade.F. (141, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (136 data points).\n",
      "old error:  0.176470588235\n",
      "new error:  0.823529411765\n",
      "Split on feature grade.F. (136, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (158 data points).\n",
      "old error:  0.196202531646\n",
      "new error:  0.803797468354\n",
      "Split on feature grade.F. (158, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (197 data points).\n",
      "old error:  0.228426395939\n",
      "new error:  0.771573604061\n",
      "Split on feature grade.F. (197, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (175 data points).\n",
      "old error:  0.182857142857\n",
      "new error:  0.817142857143\n",
      "Split on feature grade.F. (175, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (204 data points).\n",
      "old error:  0.220588235294\n",
      "new error:  0.779411764706\n",
      "Split on feature grade.F. (204, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (204 data points).\n",
      "old error:  0.191176470588\n",
      "new error:  0.808823529412\n",
      "Split on feature grade.F. (204, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (186 data points).\n",
      "old error:  0.145161290323\n",
      "new error:  0.854838709677\n",
      "Split on feature grade.F. (186, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (977 data points).\n",
      "old error:  0.205731832139\n",
      "new error:  0.794268167861\n",
      "Split on feature grade.F. (977, 0)\n",
      "Creating leaf node.\n"
     ]
    }
   ],
   "source": [
    "model_1 = decision_tree_create(train_data, features, train_Y, max_depth = 2, \n",
    "                                min_node_size = 0, min_error_reduction=-1)\n",
    "model_2 =  decision_tree_create(train_data, features, train_Y, max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=-1)\n",
    "model_3 =  decision_tree_create(train_data, features, train_Y, max_depth = 14, \n",
    "                                min_node_size = 0, min_error_reduction=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data, classification error (model 1): 0.578981302386\n",
      "Training data, classification error (model 2): 0.615382548893\n",
      "Training data, classification error (model 3): 0.616269073716\n"
     ]
    }
   ],
   "source": [
    "print (\"Training data, classification error (model 1):\", evaluate_classification_error(model_1, train_data, train_Y))\n",
    "print (\"Training data, classification error (model 2):\", evaluate_classification_error(model_2, train_data, train_Y))\n",
    "print (\"Training data, classification error (model 3):\", evaluate_classification_error(model_3, train_data, train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data, classification error (model 1): 0.577337354589\n",
      "Validation data, classification error (model 2): 0.61805256355\n",
      "Validation data, classification error (model 3): 0.618806548901\n"
     ]
    }
   ],
   "source": [
    "print (\"Validation data, classification error (model 1):\", evaluate_classification_error(model_1, test_data, test_Y))\n",
    "print (\"Validation data, classification error (model 2):\", evaluate_classification_error(model_2, test_data, test_Y))\n",
    "print (\"Validation data, classification error (model 3):\", evaluate_classification_error(model_3, test_data, test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the complexity of the tree\n",
    "\n",
    "Recall in the lecture that we talked about deeper trees being more complex. We will measure the complexity of the tree as\n",
    "\n",
    "```\n",
    "  complexity(T) = number of leaves in the tree T\n",
    "```\n",
    "\n",
    "Here, we provide a function `count_leaves` that counts the number of leaves in a tree. Using this implementation, compute the number of nodes in `model_1`, `model_2`, and `model_3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_leaves(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return count_leaves(tree['left']) + count_leaves(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complexity of model_1:  4\n",
      "complexity of model_2:  28\n",
      "complexity of model_3:  88\n"
     ]
    }
   ],
   "source": [
    "print(\"complexity of model_1: \", count_leaves(model_1))\n",
    "\n",
    "print(\"complexity of model_2: \", count_leaves(model_2))\n",
    "\n",
    "print(\"complexity of model_3: \", count_leaves(model_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the effect of min_error\n",
    "\n",
    "We will compare three models trained with different values of the stopping criterion. We intentionally picked models at the extreme ends (**negative**, **just right**, and **too positive**).\n",
    "\n",
    "Train three models with these parameters:\n",
    "1. **model_4**: `min_error_reduction = -1` (ignoring this early stopping condition)\n",
    "2. **model_5**: `min_error_reduction = 0` (just right)\n",
    "3. **model_6**: `min_error_reduction = 5` (too positive)\n",
    "\n",
    "For each of these three, we set `max_depth = 6`, and `min_node_size = 0`.\n",
    "\n",
    "** Note:** Each tree can take up to 30 seconds to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "old error:  0.496346443155\n",
      "new error:  0.421636578551\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "old error:  0.349235606636\n",
      "new error:  0.34674184105\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "old error:  0.346305634729\n",
      "new error:  0.346415259811\n",
      "Split on feature home_ownership.OTHER. (9119, 3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9119 data points).\n",
      "old error:  0.346309902402\n",
      "new error:  0.358701612019\n",
      "Split on feature emp_length.n/a. (8898, 221)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (8898 data points).\n",
      "old error:  0.348842436503\n",
      "new error:  0.362553382783\n",
      "Split on feature grade.B. (7884, 1014)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (7884 data points).\n",
      "old error:  0.337138508371\n",
      "new error:  0.354261796043\n",
      "Split on feature emp_length.8 years. (7507, 377)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7507 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (377 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1014 data points).\n",
      "old error:  0.439842209073\n",
      "new error:  0.436883629191\n",
      "Split on feature emp_length.5 years. (935, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (935 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (79 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (221 data points).\n",
      "old error:  0.244343891403\n",
      "new error:  0.244343891403\n",
      "Split on feature grade.G. (215, 6)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (215 data points).\n",
      "old error:  0.237209302326\n",
      "new error:  0.237209302326\n",
      "Split on feature emp_length.9 years. (215, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (6 data points).\n",
      "old error:  0.5\n",
      "new error:  0.166666666667\n",
      "Split on feature home_ownership.OWN. (4, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (4 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3 data points).\n",
      "old error:  0.333333333333\n",
      "new error:  0.0\n",
      "Split on feature grade.F. (2, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "old error:  0.386138613861\n",
      "new error:  0.386138613861\n",
      "Split on feature term. 60 months. (0, 101)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "old error:  0.445484089854\n",
      "new error:  0.461983500589\n",
      "Split on feature grade.A. (22972, 5029)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (22972 data points).\n",
      "old error:  0.489944279993\n",
      "new error:  0.43143827268\n",
      "Split on feature grade.B. (13654, 9318)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13654 data points).\n",
      "old error:  0.450783653142\n",
      "new error:  0.450783653142\n",
      "Split on feature term. 60 months. (13654, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9318 data points).\n",
      "old error:  0.403090792015\n",
      "new error:  0.484331401588\n",
      "Split on feature home_ownership.MORTGAGE. (4975, 4343)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4975 data points).\n",
      "old error:  0.42391959799\n",
      "new error:  0.454472361809\n",
      "Split on feature home_ownership.RENT. (738, 4237)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (738 data points).\n",
      "old error:  0.39701897019\n",
      "new error:  0.390243902439\n",
      "Split on feature home_ownership.OWN. (17, 721)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (17 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (721 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4237 data points).\n",
      "old error:  0.42860514515\n",
      "new error:  0.543072928959\n",
      "Split on feature emp_length.2 years. (3741, 496)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3741 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (496 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4343 data points).\n",
      "old error:  0.37923094635\n",
      "new error:  0.533041676261\n",
      "Split on feature emp_length.10+ years. (2846, 1497)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2846 data points).\n",
      "old error:  0.382642304989\n",
      "new error:  0.581869290232\n",
      "Split on feature emp_length.2 years. (2513, 333)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2513 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (333 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1497 data points).\n",
      "old error:  0.372745490982\n",
      "new error:  0.627254509018\n",
      "Split on feature grade.F. (1497, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5029 data points).\n",
      "old error:  0.242394114138\n",
      "new error:  0.443626963611\n",
      "Split on feature home_ownership.MORTGAGE. (2282, 2747)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2282 data points).\n",
      "old error:  0.278264680105\n",
      "new error:  0.382559158633\n",
      "Split on feature home_ownership.RENT. (458, 1824)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (458 data points).\n",
      "old error:  0.240174672489\n",
      "new error:  0.255458515284\n",
      "Split on feature home_ownership.OWN. (9, 449)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (9 data points).\n",
      "old error:  0.111111111111\n",
      "new error:  0.111111111111\n",
      "Split on feature home_ownership.OTHER. (0, 9)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (449 data points).\n",
      "old error:  0.24276169265\n",
      "new error:  0.599109131403\n",
      "Split on feature emp_length.10+ years. (318, 131)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (318 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (131 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1824 data points).\n",
      "old error:  0.287828947368\n",
      "new error:  0.644188596491\n",
      "Split on feature emp_length.< 1 year. (1564, 260)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1564 data points).\n",
      "old error:  0.292199488491\n",
      "new error:  0.642583120205\n",
      "Split on feature emp_length.2 years. (1332, 232)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1332 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (232 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (260 data points).\n",
      "old error:  0.261538461538\n",
      "new error:  0.738461538462\n",
      "Split on feature grade.F. (260, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2747 data points).\n",
      "old error:  0.212595558791\n",
      "new error:  0.578085183837\n",
      "Split on feature emp_length.10+ years. (1770, 977)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1770 data points).\n",
      "old error:  0.216384180791\n",
      "new error:  0.709039548023\n",
      "Split on feature emp_length.4 years. (1584, 186)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1584 data points).\n",
      "old error:  0.224747474747\n",
      "new error:  0.695707070707\n",
      "Split on feature emp_length.2 years. (1380, 204)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1380 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (204 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (186 data points).\n",
      "old error:  0.145161290323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new error:  0.854838709677\n",
      "Split on feature grade.F. (186, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (977 data points).\n",
      "old error:  0.205731832139\n",
      "new error:  0.794268167861\n",
      "Split on feature grade.F. (977, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "old error:  0.496346443155\n",
      "new error:  0.421636578551\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "old error:  0.349235606636\n",
      "new error:  0.34674184105\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "old error:  0.346305634729\n",
      "new error:  0.346415259811\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "old error:  0.386138613861\n",
      "new error:  0.386138613861\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "old error:  0.445484089854\n",
      "new error:  0.461983500589\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "old error:  0.496346443155\n",
      "new error:  0.421636578551\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n"
     ]
    }
   ],
   "source": [
    "model_4 = decision_tree_create(train_data, features, train_Y, max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=-1)\n",
    "model_5 =  decision_tree_create(train_data, features, train_Y, max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=0)\n",
    "model_6 =  decision_tree_create(train_data, features, train_Y, max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data, classification error (model 4): 0.615382548893\n",
      "Training data, classification error (model 5): 0.578981302386\n",
      "Training data, classification error (model 6): 0.503653556845\n"
     ]
    }
   ],
   "source": [
    "print (\"Training data, classification error (model 4):\", evaluate_classification_error(model_4, train_data, train_Y))\n",
    "print (\"Training data, classification error (model 5):\", evaluate_classification_error(model_5, train_data, train_Y))\n",
    "print (\"Training data, classification error (model 6):\", evaluate_classification_error(model_6, train_data, train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data, classification error (model 4): 0.61805256355\n",
      "Validation data, classification error (model 5): 0.577337354589\n",
      "Validation data, classification error (model 6): 0.496553209823\n"
     ]
    }
   ],
   "source": [
    "print (\"Validation data, classification error (model 4):\", evaluate_classification_error(model_4, test_data, test_Y))\n",
    "print (\"Validation data, classification error (model 5):\", evaluate_classification_error(model_5, test_data, test_Y))\n",
    "print (\"Validation data, classification error (model 6):\", evaluate_classification_error(model_6, test_data, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complexity of model_4:  28\n",
      "complexity of model_5:  3\n",
      "complexity of model_6:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"complexity of model_4: \", count_leaves(model_4))\n",
    "\n",
    "print(\"complexity of model_5: \", count_leaves(model_5))\n",
    "\n",
    "print(\"complexity of model_6: \", count_leaves(model_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the effect of min_node_size\n",
    "\n",
    "We will compare three models trained with different values of the stopping criterion. Again, intentionally picked models at the extreme ends (**too small**, **just right**, and **just right**).\n",
    "\n",
    "Train three models with these parameters:\n",
    "1. **model_7**: min_node_size = 0 (too small)\n",
    "2. **model_8**: min_node_size = 2000 (just right)\n",
    "3. **model_9**: min_node_size = 50000 (too large)\n",
    "\n",
    "For each of these three, we set `max_depth = 6`, and `min_error_reduction = -1`.\n",
    "\n",
    "** Note:** Each tree can take up to 30 seconds to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "old error:  0.496346443155\n",
      "new error:  0.421636578551\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "old error:  0.349235606636\n",
      "new error:  0.34674184105\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "old error:  0.346305634729\n",
      "new error:  0.346415259811\n",
      "Split on feature home_ownership.OTHER. (9119, 3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9119 data points).\n",
      "old error:  0.346309902402\n",
      "new error:  0.358701612019\n",
      "Split on feature emp_length.n/a. (8898, 221)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (8898 data points).\n",
      "old error:  0.348842436503\n",
      "new error:  0.362553382783\n",
      "Split on feature grade.B. (7884, 1014)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (7884 data points).\n",
      "old error:  0.337138508371\n",
      "new error:  0.354261796043\n",
      "Split on feature emp_length.8 years. (7507, 377)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7507 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (377 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1014 data points).\n",
      "old error:  0.439842209073\n",
      "new error:  0.436883629191\n",
      "Split on feature emp_length.5 years. (935, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (935 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (79 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (221 data points).\n",
      "old error:  0.244343891403\n",
      "new error:  0.244343891403\n",
      "Split on feature grade.G. (215, 6)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (215 data points).\n",
      "old error:  0.237209302326\n",
      "new error:  0.237209302326\n",
      "Split on feature emp_length.9 years. (215, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (6 data points).\n",
      "old error:  0.5\n",
      "new error:  0.166666666667\n",
      "Split on feature home_ownership.OWN. (4, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (4 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3 data points).\n",
      "old error:  0.333333333333\n",
      "new error:  0.0\n",
      "Split on feature grade.F. (2, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "old error:  0.386138613861\n",
      "new error:  0.386138613861\n",
      "Split on feature term. 60 months. (0, 101)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "old error:  0.445484089854\n",
      "new error:  0.461983500589\n",
      "Split on feature grade.A. (22972, 5029)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (22972 data points).\n",
      "old error:  0.489944279993\n",
      "new error:  0.43143827268\n",
      "Split on feature grade.B. (13654, 9318)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13654 data points).\n",
      "old error:  0.450783653142\n",
      "new error:  0.450783653142\n",
      "Split on feature term. 60 months. (13654, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9318 data points).\n",
      "old error:  0.403090792015\n",
      "new error:  0.484331401588\n",
      "Split on feature home_ownership.MORTGAGE. (4975, 4343)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4975 data points).\n",
      "old error:  0.42391959799\n",
      "new error:  0.454472361809\n",
      "Split on feature home_ownership.RENT. (738, 4237)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (738 data points).\n",
      "old error:  0.39701897019\n",
      "new error:  0.390243902439\n",
      "Split on feature home_ownership.OWN. (17, 721)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (17 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (721 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4237 data points).\n",
      "old error:  0.42860514515\n",
      "new error:  0.543072928959\n",
      "Split on feature emp_length.2 years. (3741, 496)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3741 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (496 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4343 data points).\n",
      "old error:  0.37923094635\n",
      "new error:  0.533041676261\n",
      "Split on feature emp_length.10+ years. (2846, 1497)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2846 data points).\n",
      "old error:  0.382642304989\n",
      "new error:  0.581869290232\n",
      "Split on feature emp_length.2 years. (2513, 333)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2513 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (333 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1497 data points).\n",
      "old error:  0.372745490982\n",
      "new error:  0.627254509018\n",
      "Split on feature grade.F. (1497, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5029 data points).\n",
      "old error:  0.242394114138\n",
      "new error:  0.443626963611\n",
      "Split on feature home_ownership.MORTGAGE. (2282, 2747)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2282 data points).\n",
      "old error:  0.278264680105\n",
      "new error:  0.382559158633\n",
      "Split on feature home_ownership.RENT. (458, 1824)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (458 data points).\n",
      "old error:  0.240174672489\n",
      "new error:  0.255458515284\n",
      "Split on feature home_ownership.OWN. (9, 449)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (9 data points).\n",
      "old error:  0.111111111111\n",
      "new error:  0.111111111111\n",
      "Split on feature home_ownership.OTHER. (0, 9)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (449 data points).\n",
      "old error:  0.24276169265\n",
      "new error:  0.599109131403\n",
      "Split on feature emp_length.10+ years. (318, 131)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (318 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (131 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1824 data points).\n",
      "old error:  0.287828947368\n",
      "new error:  0.644188596491\n",
      "Split on feature emp_length.< 1 year. (1564, 260)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1564 data points).\n",
      "old error:  0.292199488491\n",
      "new error:  0.642583120205\n",
      "Split on feature emp_length.2 years. (1332, 232)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1332 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (232 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (260 data points).\n",
      "old error:  0.261538461538\n",
      "new error:  0.738461538462\n",
      "Split on feature grade.F. (260, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2747 data points).\n",
      "old error:  0.212595558791\n",
      "new error:  0.578085183837\n",
      "Split on feature emp_length.10+ years. (1770, 977)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1770 data points).\n",
      "old error:  0.216384180791\n",
      "new error:  0.709039548023\n",
      "Split on feature emp_length.4 years. (1584, 186)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1584 data points).\n",
      "old error:  0.224747474747\n",
      "new error:  0.695707070707\n",
      "Split on feature emp_length.2 years. (1380, 204)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1380 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (204 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (186 data points).\n",
      "old error:  0.145161290323\n",
      "new error:  0.854838709677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature grade.F. (186, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (977 data points).\n",
      "old error:  0.205731832139\n",
      "new error:  0.794268167861\n",
      "Split on feature grade.F. (977, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "old error:  0.496346443155\n",
      "new error:  0.421636578551\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "old error:  0.349235606636\n",
      "new error:  0.34674184105\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "old error:  0.346305634729\n",
      "new error:  0.346415259811\n",
      "Split on feature home_ownership.OTHER. (9119, 3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9119 data points).\n",
      "old error:  0.346309902402\n",
      "new error:  0.358701612019\n",
      "Split on feature emp_length.n/a. (8898, 221)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (8898 data points).\n",
      "old error:  0.348842436503\n",
      "new error:  0.362553382783\n",
      "Split on feature grade.B. (7884, 1014)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (7884 data points).\n",
      "old error:  0.337138508371\n",
      "new error:  0.354261796043\n",
      "Split on feature emp_length.8 years. (7507, 377)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (7507 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (377 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1014 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (221 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "old error:  0.445484089854\n",
      "new error:  0.461983500589\n",
      "Split on feature grade.A. (22972, 5029)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (22972 data points).\n",
      "old error:  0.489944279993\n",
      "new error:  0.43143827268\n",
      "Split on feature grade.B. (13654, 9318)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13654 data points).\n",
      "old error:  0.450783653142\n",
      "new error:  0.450783653142\n",
      "Split on feature term. 60 months. (13654, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9318 data points).\n",
      "old error:  0.403090792015\n",
      "new error:  0.484331401588\n",
      "Split on feature home_ownership.MORTGAGE. (4975, 4343)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4975 data points).\n",
      "old error:  0.42391959799\n",
      "new error:  0.454472361809\n",
      "Split on feature home_ownership.RENT. (738, 4237)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (738 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4237 data points).\n",
      "old error:  0.42860514515\n",
      "new error:  0.543072928959\n",
      "Split on feature emp_length.2 years. (3741, 496)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3741 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (496 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4343 data points).\n",
      "old error:  0.37923094635\n",
      "new error:  0.533041676261\n",
      "Split on feature emp_length.10+ years. (2846, 1497)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2846 data points).\n",
      "old error:  0.382642304989\n",
      "new error:  0.581869290232\n",
      "Split on feature emp_length.2 years. (2513, 333)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2513 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (333 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1497 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5029 data points).\n",
      "old error:  0.242394114138\n",
      "new error:  0.443626963611\n",
      "Split on feature home_ownership.MORTGAGE. (2282, 2747)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2282 data points).\n",
      "old error:  0.278264680105\n",
      "new error:  0.382559158633\n",
      "Split on feature home_ownership.RENT. (458, 1824)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (458 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1824 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2747 data points).\n",
      "old error:  0.212595558791\n",
      "new error:  0.578085183837\n",
      "Split on feature emp_length.10+ years. (1770, 977)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1770 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (977 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n"
     ]
    }
   ],
   "source": [
    "model_7 = decision_tree_create(train_data, features, train_Y, max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=-1)\n",
    "model_8 =  decision_tree_create(train_data, features, train_Y, max_depth = 6, \n",
    "                                min_node_size = 2000, min_error_reduction=-1)\n",
    "model_9 =  decision_tree_create(train_data, features, train_Y, max_depth = 6, \n",
    "                                min_node_size = 50000, min_error_reduction=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data, classification error (model 7): 0.61805256355\n",
      "Validation data, classification error (model 8): 0.618375700129\n",
      "Validation data, classification error (model 9): 0.496553209823\n"
     ]
    }
   ],
   "source": [
    "print (\"Validation data, classification error (model 7):\", evaluate_classification_error(model_7, test_data, test_Y))\n",
    "print (\"Validation data, classification error (model 8):\", evaluate_classification_error(model_8, test_data, test_Y))\n",
    "print (\"Validation data, classification error (model 9):\", evaluate_classification_error(model_9, test_data, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data, classification error (model 7): 0.615382548893\n",
      "Training data, classification error (model 8): 0.615087040619\n",
      "Training data, classification error (model 9): 0.503653556845\n"
     ]
    }
   ],
   "source": [
    "print (\"Training data, classification error (model 7):\", evaluate_classification_error(model_7, train_data, train_Y))\n",
    "print (\"Training data, classification error (model 8):\", evaluate_classification_error(model_8, train_data, train_Y))\n",
    "print (\"Training data, classification error (model 9):\", evaluate_classification_error(model_9, train_data, train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complexity of model_7:  28\n",
      "complexity of model_8:  17\n",
      "complexity of model_9:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"complexity of model_7: \", count_leaves(model_7))\n",
    "\n",
    "print(\"complexity of model_8: \", count_leaves(model_8))\n",
    "\n",
    "print(\"complexity of model_9: \", count_leaves(model_9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
