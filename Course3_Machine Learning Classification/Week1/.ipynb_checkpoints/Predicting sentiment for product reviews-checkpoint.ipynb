{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews\n",
    "\n",
    "\n",
    "The goal of this first notebook is to explore logistic regression and feature engineering with existing GraphLab functions.\n",
    "\n",
    "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models.\n",
    "\n",
    "Let's get started!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'name':str,\n",
    "              'review':str, \n",
    "              'rating':int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby.csv', dtype = dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review\n",
    "\n",
    "Let us explore a specific example of a baby product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183531, 3)\n",
      "['The First Years Massaging Action Teether' 'A favorite in our house!' 5]\n"
     ]
    }
   ],
   "source": [
    "products_matrix = products.values\n",
    "print(products_matrix.shape)\n",
    "print(products_matrix[269])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Transform the reviews into word-counts.\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://www.cis.upenn.edu/~treebank/tokenization.html) for an example of smart handling of punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['review_without_punctuation']=products['review'].str.replace('[{}]'.format(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These flannel wipes are OK, but in my opinion not worth keeping.  I also ordered someImse Vimse Cloth Wipes-Ocean Blue-12 countwhich are larger, had a nicer, softer texture and just seemed higher quality.  I use cloth wipes for hands and faces and have been usingThirsties 6 Pack Fab Wipes, Boyfor about 8 months now and need to replace them because they are starting to get rough and have had stink issues for a while that stripping no longer handles.\n"
     ]
    }
   ],
   "source": [
    "print(products['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These flannel wipes are OK but in my opinion not worth keeping  I also ordered someImse Vimse Cloth WipesOcean Blue12 countwhich are larger had a nicer softer texture and just seemed higher quality  I use cloth wipes for hands and faces and have been usingThirsties 6 Pack Fab Wipes Boyfor about 8 months now and need to replace them because they are starting to get rough and have had stink issues for a while that stripping no longer handles\n"
     ]
    }
   ],
   "source": [
    "print(products['review_without_punctuation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [name, review, rating, review_without_punctuation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(products.head(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products[products['rating'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['sentiments'] = products['rating'].apply(lambda rating: 1 if rating > 3 \n",
    "                                                 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166752, 5)\n"
     ]
    }
   ],
   "source": [
    "print(products.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'review', 'rating', 'review_without_punctuation', 'sentiments']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(products.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33336\n",
      "(33336, 5)\n"
     ]
    }
   ],
   "source": [
    "with open('test-idx.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "print(len(test_data))\n",
    "test_data = pd.DataFrame(products.values[test_data])\n",
    "test_data.columns = list(products.columns.values)\n",
    "\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133416\n",
      "(133416, 5)\n"
     ]
    }
   ],
   "source": [
    "with open('train-idx.json', 'r') as f:\n",
    "    train_data= json.load(f)\n",
    "print(len(train_data))\n",
    "\n",
    "train_data = pd.DataFrame(products.values[train_data])\n",
    "train_data.columns = list(products.columns.values)\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review\n",
    "\n",
    "We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as bag-of-word features. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:\n",
    "\n",
    "* Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "\n",
    "* Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "\n",
    "* Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix.\n",
    "\n",
    "* Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell uses CountVectorizer in scikit-learn. Notice the token_pattern argument in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_without_punctuation'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_without_punctuation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133416, 121706)\n"
     ]
    }
   ],
   "source": [
    "print(train_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data.\n",
    "\n",
    "Learn a logistic regression classifier using the training data. If you are using scikit-learn, you should create an instance of the LogisticRegression class and then call the method ```fit()``` to train the classifier. This model should use the sparse word count matrix (```train_matrix```) as features and the column sentiment of train_data as the target. Use the default values for other parameters. Call this model sentiment_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output = train_data['sentiments']\n",
    "train_output=train_output.astype('int')\n",
    "type(train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133416, 121706)\n",
      "(133416, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_matrix.shape)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model = linear_model.LogisticRegression()\n",
    "sentiment_model.fit(train_matrix, train_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be over 100,000 coefficients in this sentiment_model. Recall from the lecture that positive weights ```w_j``` correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. Calculate the number of positive (```>= 0```, which is actually nonnegative) coefficients.\n",
    "\n",
    "**Quiz question: How many weights are >= 0?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85837\n",
      "35869\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print((sentiment_model.coef_>0).sum())\n",
    "print((sentiment_model.coef_<0).sum())\n",
    "print((sentiment_model.coef_==0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the test data. In this section, we will explore this in the context of 3 data points in the test data. Take the 11th, 12th, and 13th data points in the test data and save them to sample_test_data. The following cell extracts the three data points from the SFrame test_data and print their content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13]\n",
    "print(sample_test_data.shape)\n",
    "\n",
    "sample_test_matrix = test_matrix[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 name  \\\n",
      "10                          Our Baby Girl Memory Book   \n",
      "11  Wall Decor Removable Decal Sticker - Colorful ...   \n",
      "12  New Style Trailing Cherry Blossom Tree Decal R...   \n",
      "\n",
      "                                               review rating  \\\n",
      "10  Absolutely love it and all of the Scripture in...      5   \n",
      "11  Would not purchase again or recommend. The dec...      2   \n",
      "12  Was so excited to get this product for my baby...      1   \n",
      "\n",
      "                           review_without_punctuation sentiments  \n",
      "10  Absolutely love it and all of the Scripture in...          1  \n",
      "11  Would not purchase again or recommend The deca...         -1  \n",
      "12  Was so excited to get this product for my baby...         -1  \n"
     ]
    }
   ],
   "source": [
    "print(sample_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_test_output= sample_test_data['sentiments']\n",
    "sample_test_output=sample_test_output.astype('int')\n",
    "\n",
    "sample_predictions = sentiment_model.predict(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(sample_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a **class** prediction for the **sample_test_data**. The `sentiment_model` should predict **+1** if the sentiment is positive and **-1** if the sentiment is negative. Recall from the lecture that the **score** (sometimes called **margin**) for the logistic regression model  is defined as:\n",
    "\n",
    "$$\n",
    "\\mbox{score}_i = \\mathbf{w}^T h(\\mathbf{x}_i)\n",
    "$$ \n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for example $i$.  We will write some code to obtain the **scores** using GraphLab Create. For each row, the **score** (or margin) is a number in the range **[-inf, inf]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.59355542  -3.13902441 -10.40249874]\n"
     ]
    }
   ],
   "source": [
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate $\\hat{y}$, the class predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your class predictions match with the one obtained from GraphLab Create.\n",
    "\n",
    "### Probability predictions\n",
    "\n",
    "Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))}.\n",
    "$$\n",
    "\n",
    "Using the variable **scores** calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range **[0, 1]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.96292028e-01   4.15259321e-02   3.03556134e-05]\n",
      "[ True False False]\n"
     ]
    }
   ],
   "source": [
    "p = 1/(1+np.exp(-scores))\n",
    "print(p)\n",
    "print(p>=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most positive (and negative) review\n",
    "\n",
    "We now turn to examining the full test dataset, **test_data**, to form predictions on all of the test data points for faster performance.\n",
    "\n",
    "Using the `sentiment_model`, find the 20 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "1.  Make probability predictions on **test_data** using the `sentiment_model`. (**Hint:** When you call `.predict` to make predictions on the test data, use option `output_type='probability'` to output the probability rather than just the most likely class.)\n",
    "2.  Sort the data according to those predictions and pick the top 20. (**Hint:** You can use the `.topk` method on an SFrame to find the top k rows sorted according to the value of a specified column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_all = sentiment_model.decision_function(test_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores_all_index = np.argsort(-scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 53.55701871  51.96795627  48.23815669  46.3150606   44.12976888\n",
      "  43.08579024  41.93927841  40.82291962  40.55038703  40.42484511\n",
      "  40.1667546   39.86017685  38.87524658  38.11059032  37.59445731\n",
      "  37.55648131  36.24387372  36.19483965  35.35932833  35.22911277]\n",
      "[18112 15732 24286 25554 24899  9125 21531 32782  9555 30535 14482 30634\n",
      " 17558 26830 20743 11923  4140 30076 26838 33060]\n"
     ]
    }
   ],
   "source": [
    "print(scores_all[sorted_scores_all_index[0:20]])\n",
    "print(sorted_scores_all_index[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_test_name = test_data['name'][sorted_scores_all_index[0:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18112    Infantino Wrap and Tie Baby Carrier, Black Blu...\n",
      "15732      Baby Einstein Around The World Discovery Center\n",
      "24286                    Britax 2012 B-Agile Stroller, Red\n",
      "25554           Diono RadianRXT Convertible Car Seat, Plum\n",
      "24899           Graco Pack 'n Play Element Playard - Flint\n",
      "9125            P'Kolino Silly Soft Seating in Tias, Green\n",
      "21531    Roan Rocco Classic Pram Stroller 2-in-1 with B...\n",
      "32782        Mamas &amp; Papas 2014 Urbo2 Stroller - Black\n",
      "9555     Evenflo X Sport Plus Convenience Stroller - Ch...\n",
      "30535    Buttons Cloth Diaper Cover - One Size - 8 Colo...\n",
      "14482    Simple Wishes Hands-Free Breastpump Bra, Pink,...\n",
      "30634    Graco FastAction Fold Jogger Click Connect Str...\n",
      "17558    Freemie Hands-Free Concealable Breast Pump Col...\n",
      "26830    Baby Jogger City Mini GT Single Stroller, Shad...\n",
      "20743    Fisher-Price Cradle 'N Swing,  My Little Snuga...\n",
      "11923         Evenflo 6 Pack Classic Glass Bottle, 4-Ounce\n",
      "4140        Britax Decathlon Convertible Car Seat, Tiffany\n",
      "30076    Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...\n",
      "26838    Baby Jogger City Mini GT Double Stroller, Shad...\n",
      "33060    Summer Infant Wide View Digital Color Video Mo...\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(top_20_test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5831                Regalo My Cot Portable Bed, Royal Blue\n",
      "15062        Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs\n",
      "205                  Safety 1st Deluxe 4-in-1 Bath Station\n",
      "28120    VTech Communications Safe &amp; Sound Digital ...\n",
      "7310     Chicco Cortina KeyFit 30 Travel System in Adve...\n",
      "27231                     NUK Cook-n-Blend Baby Food Maker\n",
      "31226    Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...\n",
      "13751           Peg-Perego Tatamia High Chair, White Latte\n",
      "10814               Ellaroo Mei Tai Baby Carrier - Hershey\n",
      "1810          Cosco Alpha Omega Elite Convertible Car Seat\n",
      "1942                     Philips AVENT Newborn Starter Set\n",
      "20594    Motorola Digital Video Baby Monitor with Room ...\n",
      "14711                Cloth Diaper Sprayer--styles may vary\n",
      "9655                   Safety 1st High-Def Digital Monitor\n",
      "17069    The First Years True Choice P400 Premium Digit...\n",
      "28184    VTech Communications Safe &amp; Sounds Full Co...\n",
      "8818     Adiri BPA Free Natural Nurser Ultimate Bottle ...\n",
      "13939       Safety 1st Exchangeable Tip 3 in 1 Thermometer\n",
      "21700    Levana Safe N'See Digital Video Baby Monitor w...\n",
      "2931           Fisher-Price Ocean Wonders Aquarium Bouncer\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "low_20_test_name = test_data['name'][sorted_scores_all_index[-20:]]\n",
    "print(low_20_test_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 20 most negative reviews?  [multiple choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifier. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "* **Step 1:** Use the trained model to compute class predictions (**Hint:** Use the `predict` method)\n",
    "* **Step 2:** Count the number of data points when the predicted class labels match the ground truth labels (called `true_labels` below).\n",
    "* **Step 3:** Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    # First get the predictions\n",
    "    \n",
    "    predictions = model.predict(data)\n",
    "    \n",
    "    # Compute the number of correctly classified examples\n",
    "    accuracy = (predictions == true_labels).sum()/(len(true_labels))\n",
    "\n",
    "    # Then compute accuracy by dividing num_correct by total number of examples\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_output = test_data['sentiments']\n",
    "test_output = test_output.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93238540916726664"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, test_matrix, test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn another classifier with fewer words\n",
    "\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subset of words that occur in the reviews. For this assignment, we selected a 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a new set of word count vectors using only these words. The ```CountVectorizer``` class has a parameter that lets you limit the choice of words when building word count vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_without_punctuation'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_without_punctuation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression model on a subset of data\n",
    "We will now build a classifier with **word_count_subset** as the feature and **sentiment** as the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = linear_model.LogisticRegression()\n",
    "simple_model.fit(train_matrix_word_subset, train_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the classification accuracy using the `get_classification_accuracy` function you implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86936045116390692"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, test_matrix_word_subset, test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will inspect the weights (coefficients) of the simple_model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36368827,  0.94399786,  1.19253652,  0.08550919,  0.52018333,\n",
       "         1.50981028,  1.67311805,  0.50375862,  0.19090598,  0.05885356,\n",
       "        -1.65157706, -0.2095648 , -0.51138168, -2.03369873, -2.34830004,\n",
       "        -0.62117042, -0.32055792, -0.89803241, -0.36215621, -2.10933278]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Consider the coefficients of **simple_model**. There should be 21 of them, an intercept term + one for each word in **significant_words**. How many of the 20 coefficients (corresponding to the 20 **significant_words** and *excluding the intercept term*) are positive for the `simple_model`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print((simple_model.coef_>0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(simple_model.coef_).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  coef\n",
      "love          1.363688\n",
      "great         0.943998\n",
      "easy          1.192537\n",
      "old           0.085509\n",
      "little        0.520183\n",
      "perfect       1.509810\n",
      "loves         1.673118\n",
      "well          0.503759\n",
      "able          0.190906\n",
      "car           0.058854\n",
      "broke        -1.651577\n",
      "less         -0.209565\n",
      "even         -0.511382\n",
      "waste        -2.033699\n",
      "disappointed -2.348300\n",
      "work         -0.621170\n",
      "product      -0.320558\n",
      "money        -0.898032\n",
      "would        -0.362156\n",
      "return       -2.109333\n"
     ]
    }
   ],
   "source": [
    "columns = ['coef']\n",
    "index = significant_words\n",
    "\n",
    "simple_model_result = pd.DataFrame(np.transpose(np.asarray(simple_model.coef_)), columns=columns, index=index)\n",
    "\n",
    "print(simple_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Are the positive words in the **simple_model** (let us call them `positive_significant_words`) also positive words in the **sentiment_model**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', 'well',\n",
      "       'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', 'work',\n",
      "       'product', 'money', 'would', 'return'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(simple_model_result.index)\n",
    "list_all_coefficient = np.transpose(sentiment_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.23330228e+00]\n",
      " [  2.37538251e-04]\n",
      " [  2.55429984e-02]\n",
      " ..., \n",
      " [  1.10903893e-02]\n",
      " [  3.24828215e-03]\n",
      " [ -7.75234981e-05]]\n",
      "(121706, 1)\n"
     ]
    }
   ],
   "source": [
    "print(list_all_coefficient)\n",
    "print(list_all_coefficient.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "testing_result = 1\n",
    "counting = 0\n",
    "for word in simple_model_result.index:\n",
    "    if simple_model_result.values[counting]>0:\n",
    "        index = vectorizer.vocabulary_.get(word)\n",
    "        if list_all_coefficient[index]>0:\n",
    "            testing_result = testing_result  * 1\n",
    "        else:\n",
    "            testing_result = testing_result * 0\n",
    "    counting +=1\n",
    "print(testing_result)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models\n",
    "\n",
    "We will now compare the accuracy of the **sentiment_model** and the **simple_model** using the `get_classification_accuracy` method you implemented above.\n",
    "\n",
    "First, compute the classification accuracy of the **sentiment_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96746267314265155"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model = linear_model.LogisticRegression()\n",
    "sentiment_model.fit(train_matrix, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96746267314265155"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, train_matrix, train_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the classification accuracy of the **simple_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668225700065959"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, train_matrix_word_subset, train_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TRAINING set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will repeat this exercise on the **test_data**. Start by computing the classification accuracy of the **sentiment_model** on the **test_data**:\n",
    "\n",
    "Actually, we have done this previously. Here, we just simply call the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93238540916726664"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, test_matrix, test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86936045116390692"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, test_matrix_word_subset, test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should healthily beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n",
    "What is the majority class in the **train_data**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28095\n",
      "5241\n"
     ]
    }
   ],
   "source": [
    "num_positive  = (test_output == +1).sum()\n",
    "num_negative = (test_output == -1).sum()\n",
    "print(num_positive)\n",
    "print (num_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the accuracy of the majority class classifier on **test_data**.\n",
    "\n",
    "**Quiz Question**: Enter the accuracy of the majority class classifier model on the **test_data**. Round your answer to two decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84278257739380846"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_positive/(num_positive+num_negative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
