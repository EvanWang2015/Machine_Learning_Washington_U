{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load review dataset\n",
    "\n",
    "For this assignment, we will use a subset of the Amazon product review dataset. The subset was chosen to contain similar numbers of positive and negative reviews, as the original dataset consisted primarily of positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  \n",
       "1  We wanted to get something to keep track of ou...       5          1  \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3  One of baby's first and favorite books, and it...       4          1  \n",
       "4  Very cute interactive book! My son loves this ...       5          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of positive review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26579"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(products['sentiment']>0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of negative review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26493"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(products['sentiment']<0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply text cleaning on the review data\n",
    "\n",
    "In this section, we will perform some simple feature cleaning using data frames. The last assignment used all words in building bag-of-words features, but here we limit ourselves to 193 words (for simplicity). We compiled a list of 193 most frequent words into the JSON file named important_words.json. Load the words into a list ```important_words```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('important_words.json', 'r') as f:\n",
    "    important_words= json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us perform data transformations:\n",
    "\n",
    "* Remove punctuation\n",
    "* Compute word counts (only for important_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your tool supports it, fill n/a values in the review column with empty strings. The n/a values indicate empty reviews. For instance, Pandas's the ```fillna()``` method lets you replace all N/A's in the review columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "products['review_clean']=products['review'].str.replace('[{}]'.format(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "3  One of baby's first and favorite books, and it...       4          1   \n",
       "4  Very cute interactive book! My son loves this ...       5          1   \n",
       "\n",
       "                                        review_clean  \n",
       "0  All of my kids have cried nonstop when I tried...  \n",
       "1  We wanted to get something to keep track of ou...  \n",
       "2  My daughter had her 1st baby over a year ago S...  \n",
       "3  One of babys first and favorite books and it i...  \n",
       "4  Very cute interactive book My son loves this b...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed with the second item. For each word in **important_words**, we compute a count for the number of times the word occurs in the review. We will store this count in a separate column (one for each word). The result of this feature processing is a single column for each word in **important_words** which keeps a count of the number of times the respective word occurs in the review text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_matrix = pd.DataFrame()\n",
    "\n",
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072, 198)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write some code to compute the number of product reviews that contain the word **perfect**.\n",
    "\n",
    "**Hint**: \n",
    "* First create a column called `contains_perfect` which is set to 1 if the count of the word **perfect** (stored in column **perfect**) is >= 1.\n",
    "* Sum the number of 1s in the column `contains_perfect`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. How many reviews contain the word **perfect**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((products['perfect'].values)>0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NumPy array\n",
    "\n",
    "As you have seen previously, NumPy is a powerful library for doing matrix manipulation. Let us convert our data to matrices and then implement our algorithms with matrices.\n",
    "\n",
    "First, make sure you can perform the following import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_Dframe, features, label):\n",
    "    data_Dframe['intercept'] = 1\n",
    "    features = ['intercept'] + features\n",
    "    features_matrix = data_Dframe[features]\n",
    "    #feature_matrix = features_sframe.to_numpy()\n",
    "    label_array = data_Dframe[label]\n",
    "    \n",
    "    return(features_matrix, label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us convert the data into NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix, sentiment = get_numpy_data(products, important_words, 'sentiment') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072, 194)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question:** How many features are there in the **feature_matrix**?\n",
    "\n",
    "** Quiz Question:** Assuming that the intercept is present, how does the number of features in **feature_matrix** relate to the number of features in the logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating conditional probability with link function\n",
    "\n",
    "Recall from lecture that the link function is given by:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$\n",
    "\n",
    "where the feature vector $h(\\mathbf{x}_i)$ represents the word counts of **important_words** in the review  $\\mathbf{x}_i$. Complete the following function that implements the link function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside**. How the link function works with matrix algebra\n",
    "\n",
    "Since the word counts are stored as columns in **feature_matrix**, each $i$-th row of the matrix corresponds to the feature vector $h(\\mathbf{x}_i)$:\n",
    "$$\n",
    "[\\text{feature_matrix}] =\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "h(\\mathbf{x}_1)^T \\\\\n",
    "h(\\mathbf{x}_2)^T \\\\\n",
    "\\vdots \\\\\n",
    "h(\\mathbf{x}_N)^T\n",
    "\\end{array}\n",
    "\\right] =\n",
    "\\left[\n",
    "\\begin{array}{cccc}\n",
    "h_0(\\mathbf{x}_1) & h_1(\\mathbf{x}_1) & \\cdots & h_D(\\mathbf{x}_1) \\\\\n",
    "h_0(\\mathbf{x}_2) & h_1(\\mathbf{x}_2) & \\cdots & h_D(\\mathbf{x}_2) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "h_0(\\mathbf{x}_N) & h_1(\\mathbf{x}_N) & \\cdots & h_D(\\mathbf{x}_N)\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "By the rules of matrix multiplication, the score vector containing elements $\\mathbf{w}^T h(\\mathbf{x}_i)$ is obtained by multiplying **feature_matrix** and the coefficient vector $\\mathbf{w}$.\n",
    "$$\n",
    "[\\text{score}] =\n",
    "[\\text{feature_matrix}]\\mathbf{w} =\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "h(\\mathbf{x}_1)^T \\\\\n",
    "h(\\mathbf{x}_2)^T \\\\\n",
    "\\vdots \\\\\n",
    "h(\\mathbf{x}_N)^T\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\mathbf{w}\n",
    "= \\left[\n",
    "\\begin{array}{c}\n",
    "h(\\mathbf{x}_1)^T\\mathbf{w} \\\\\n",
    "h(\\mathbf{x}_2)^T\\mathbf{w} \\\\\n",
    "\\vdots \\\\\n",
    "h(\\mathbf{x}_N)^T\\mathbf{w}\n",
    "\\end{array}\n",
    "\\right]\n",
    "= \\left[\n",
    "\\begin{array}{c}\n",
    "\\mathbf{w}^T h(\\mathbf{x}_1) \\\\\n",
    "\\mathbf{w}^T h(\\mathbf{x}_2) \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{w}^T h(\\mathbf{x}_N)\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "estimate ranges between 0 and 1.\n",
    "'''\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    #scores = np.dot(coefficients, feature_matrix)\n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    predictions = 1/(1.+np.exp(-scores))\n",
    "     \n",
    "    # return predictions\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing `predict_probability ()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [ 0.98201379  0.26894142]\n",
      "output of predict_probability = [ 0.98201379  0.26894142]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print ('The following outputs must match ')\n",
    "print ('------------------------------------------------')\n",
    "print ('correct_predictions           =', correct_predictions)\n",
    "print ('output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute derivative of log likelihood with respect to a single coefficient\n",
    "\n",
    "Recall from lecture:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$\n",
    "\n",
    "We will now write a function that computes the derivative of log likelihood with respect to a single coefficient $w_j$. The function accepts two arguments:\n",
    "* `errors` vector containing $\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})$ for all $i$.\n",
    "* `feature` vector containing $h_j(\\mathbf{x}_i)$  for all $i$. \n",
    "\n",
    "Complete the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):     \n",
    "    # Compute the dot product of errors and feature\n",
    "    #derivative = np.dot(errors, feature)\n",
    "    derivative = np.dot(feature, errors)\n",
    "    # Return the derivative\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the main lecture, our focus was on the likelihood.  In the advanced optional video, however, we introduced a transformation of this likelihood---called the log likelihood---that simplifies the derivation of the gradient and is more numerically stable.  Due to its numerical stability, we will use the log likelihood instead of the likelihood to assess the algorithm.\n",
    "\n",
    "The log likelihood is computed using the following formula (see the advanced optional video if you are curious about the derivation of this equation):\n",
    "\n",
    "$$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) $$\n",
    "\n",
    "We provide a function to compute the log likelihood for the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator = (sentiment == 1)\n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    log_exp = np.log(1. + np.exp(-score))\n",
    "    \n",
    "    # Simple check to prevent overflow\n",
    "    mask = np.isinf(log_exp)\n",
    "    log_exp[mask] = -score[mask]\n",
    "    \n",
    "    lp = np.sum((indicator-1)*score - log_exp)\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**\n",
    "\n",
    "Just to make sure we are on the same page, run the following code block and check that the outputs match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_log_likelihood           = -5.33141161544\n",
      "output of compute_log_likelihood = -5.33141161544\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "dummy_sentiment = np.array([-1, 1])\n",
    "\n",
    "correct_indicators  = np.array( [ -1==+1,                                       1==+1 ] )\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),                     1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_first_term  = np.array( [ (correct_indicators[0]-1)*correct_scores[0],  (correct_indicators[1]-1)*correct_scores[1] ] )\n",
    "correct_second_term = np.array( [ np.log(1. + np.exp(-correct_scores[0])),      np.log(1. + np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "correct_ll          =      sum( [ correct_first_term[0]-correct_second_term[0], correct_first_term[1]-correct_second_term[1] ] ) \n",
    "\n",
    "print( 'The following outputs must match ')\n",
    "print ('------------------------------------------------')\n",
    "print ('correct_log_likelihood           =', correct_ll)\n",
    "print ('output of compute_log_likelihood =', compute_log_likelihood(dummy_feature_matrix, dummy_sentiment, dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking gradient steps\n",
    "\n",
    "Now we are ready to implement our own logistic regression. All we have to do is to write a gradient ascent function that takes gradient steps towards the optimum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
    "    \n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in range(max_iter):\n",
    "\n",
    "        # Predict P(y_i = +1|x_i,w) using your predict_probability() function\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "        \n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "        \n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "       # for j in xrange(len(coefficients)): # loop over each coefficient\n",
    "            \n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n",
    "            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "        derivative = feature_derivative(feature_matrix, errors)\n",
    "            \n",
    "            # add the step size times the derivative to the current coefficient\n",
    "        coefficients = coefficients + step_size * derivative    \n",
    "            \n",
    "        \n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            print ('iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp))\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us run the logistic regression solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "iteration   1: log likelihood of observed labels = -36775.13434712\n",
      "iteration   2: log likelihood of observed labels = -36769.35713564\n",
      "iteration   3: log likelihood of observed labels = -36763.58603240\n",
      "iteration   4: log likelihood of observed labels = -36757.82101961\n",
      "iteration   5: log likelihood of observed labels = -36752.06207964\n",
      "iteration   6: log likelihood of observed labels = -36746.30919497\n",
      "iteration   7: log likelihood of observed labels = -36740.56234821\n",
      "iteration   8: log likelihood of observed labels = -36734.82152213\n",
      "iteration   9: log likelihood of observed labels = -36729.08669961\n",
      "iteration  10: log likelihood of observed labels = -36723.35786366\n",
      "iteration  11: log likelihood of observed labels = -36717.63499744\n",
      "iteration  12: log likelihood of observed labels = -36711.91808422\n",
      "iteration  13: log likelihood of observed labels = -36706.20710739\n",
      "iteration  14: log likelihood of observed labels = -36700.50205049\n",
      "iteration  15: log likelihood of observed labels = -36694.80289716\n",
      "iteration  20: log likelihood of observed labels = -36666.39512033\n",
      "iteration  30: log likelihood of observed labels = -36610.01327118\n",
      "iteration  40: log likelihood of observed labels = -36554.19728365\n",
      "iteration  50: log likelihood of observed labels = -36498.93316099\n",
      "iteration  60: log likelihood of observed labels = -36444.20783914\n",
      "iteration  70: log likelihood of observed labels = -36390.00909449\n",
      "iteration  80: log likelihood of observed labels = -36336.32546144\n",
      "iteration  90: log likelihood of observed labels = -36283.14615871\n",
      "iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "iteration 300: log likelihood of observed labels = -35268.51212683\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix.values, sentiment, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1e-7, max_iter=301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** As each iteration of gradient ascent passes, does the log likelihood increase or decrease?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting sentiments\n",
    "\n",
    "Recall from lecture that class predictions for a data point $\\mathbf{x}$ can be computed from the coefficients $\\mathbf{w}$ using the following formula:\n",
    "$$\n",
    "\\hat{y}_i = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{x}_i^T\\mathbf{w} > 0 \\\\\n",
    "      -1 & \\mathbf{x}_i^T\\mathbf{w} \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Now, we will write some code to compute class predictions. We will do this in two steps:\n",
    "* **Step 1**: First compute the **scores** using **feature_matrix** and **coefficients** using a dot product.\n",
    "* **Step 2**: Using the formula above, compute the class predictions from the scores.\n",
    "\n",
    "Step 1 can be implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = np.dot(feature_matrix, coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05104571, -0.02936473,  0.02411584,  0.00786905,  0.13181932,\n",
       "        0.12983486,  0.00803533,  0.03976542,  0.00732902, -0.05231529])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_sentiment[scores>0] = 1\n",
    "predicted_sentiment[scores<=0]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,  1, -1,  1, -1, -1,\n",
       "        1, -1,  1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sentiment[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question: ** How many reviews were predicted to have positive sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25126"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_sentiment>0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy\n",
    "\n",
    "We will now measure the classification accuracy of the model. Recall from the lecture that the classification accuracy can be computed as follows:\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified data points}}{\\mbox{# total data points}}\n",
    "$$\n",
    "\n",
    "Complete the following code block to compute the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518653904130238"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (predicted_sentiment == sentiment ).sum()/(len(sentiment))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "# Reviews   correctly classified = 39903\n",
      "# Reviews incorrectly classified = 13169\n",
      "# Reviews total                  = 53072\n",
      "-----------------------------------------------------\n",
      "Accuracy = 0.75\n"
     ]
    }
   ],
   "source": [
    "num_mistakes = (predicted_sentiment != sentiment ).sum()\n",
    "accuracy = (predicted_sentiment == sentiment ).sum()/(len(sentiment))\n",
    "print (\"-----------------------------------------------------\")\n",
    "print ('# Reviews   correctly classified =', len(products) - num_mistakes)\n",
    "print ('# Reviews incorrectly classified =', num_mistakes)\n",
    "print ('# Reviews total                  =', len(products))\n",
    "print (\"-----------------------------------------------------\")\n",
    "print ('Accuracy = %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: What is the accuracy of the model on predictions made above? (round to 2 digits of accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which words contribute most to positive & negative sentiments?\n",
    "\n",
    "Recall that in Module 2 assignment, we were able to compute the \"**most positive words**\". These are words that correspond most strongly with positive reviews. In order to do this, we will first do the following:\n",
    "* Treat each coefficient as a tuple, i.e. (**word**, **coefficient_value**).\n",
    "* Sort all the (**word**, **coefficient_value**) tuples by **coefficient_value** in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuple_coe = pd.DataFrame(coefficients[1:])\n",
    "tuple_coe.columns = ['coefficients']\n",
    "\n",
    "tuple_coe['words'] = important_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = list(coefficients[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, **word_coefficient_tuples** contains a sorted list of (**word**, **coefficient_value**) tuples. The first 10 elements in this list correspond to the words that are most positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.066546084170457695),\n",
       " ('love', 0.065890762922123217),\n",
       " ('easy', 0.06479458680257838),\n",
       " ('little', 0.045435626308421392),\n",
       " ('loves', 0.044976401394906045),\n",
       " ('well', 0.030135001092107063),\n",
       " ('perfect', 0.029739937104968445),\n",
       " ('old', 0.020077541034775399),\n",
       " ('nice', 0.018408707995268992),\n",
       " ('daughter', 0.017703199905701694)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ten \"most negative\" words\n",
    "\n",
    "Next, we repeat this exercise on the 10 most negative words.  That is, we compute the 10 words that have the most negative coefficient values. These words are associated with negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('monitor', -0.024482100545891713),\n",
       " ('return', -0.026592778462247273),\n",
       " ('back', -0.027742697230661331),\n",
       " ('get', -0.028711552980192553),\n",
       " ('disappointed', -0.028978976142317064),\n",
       " ('even', -0.030051249236035808),\n",
       " ('work', -0.033069515294752716),\n",
       " ('money', -0.038982037286487116),\n",
       " ('product', -0.04151103339210889),\n",
       " ('would', -0.053860148445203142)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
